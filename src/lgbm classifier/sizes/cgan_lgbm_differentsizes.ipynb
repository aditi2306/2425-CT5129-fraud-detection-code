{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CGAN with LGBM as classifier with different data sizes"
      ],
      "metadata": {
        "id": "9k1JXiVyQRgC"
      },
      "id": "9k1JXiVyQRgC"
    },
    {
      "cell_type": "markdown",
      "id": "95b87982",
      "metadata": {
        "id": "95b87982"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2d1424",
      "metadata": {
        "id": "cb2d1424"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,\\\n",
        "                            accuracy_score, balanced_accuracy_score,classification_report,\\\n",
        "                            confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QgenRhZYJcmv",
      "metadata": {
        "id": "QgenRhZYJcmv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a60195",
      "metadata": {
        "id": "90a60195"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bf21d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bf21d7",
        "outputId": "103f2f5c-42dd-4e8f-dcfd-11fdadfbc739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      284807 non-null  float64\n",
            " 1   V2      284807 non-null  float64\n",
            " 2   V3      284807 non-null  float64\n",
            " 3   V4      284807 non-null  float64\n",
            " 4   V5      284807 non-null  float64\n",
            " 5   V6      284807 non-null  float64\n",
            " 6   V7      284807 non-null  float64\n",
            " 7   V8      284807 non-null  float64\n",
            " 8   V9      284807 non-null  float64\n",
            " 9   V10     284807 non-null  float64\n",
            " 10  V11     284807 non-null  float64\n",
            " 11  V12     284807 non-null  float64\n",
            " 12  V13     284807 non-null  float64\n",
            " 13  V14     284807 non-null  float64\n",
            " 14  V15     284807 non-null  float64\n",
            " 15  V16     284807 non-null  float64\n",
            " 16  V17     284807 non-null  float64\n",
            " 17  V18     284807 non-null  float64\n",
            " 18  V19     284807 non-null  float64\n",
            " 19  V20     284807 non-null  float64\n",
            " 20  V21     284807 non-null  float64\n",
            " 21  V22     284807 non-null  float64\n",
            " 22  V23     284807 non-null  float64\n",
            " 23  V24     284807 non-null  float64\n",
            " 24  V25     284807 non-null  float64\n",
            " 25  V26     284807 non-null  float64\n",
            " 26  V27     284807 non-null  float64\n",
            " 27  V28     284807 non-null  float64\n",
            " 28  Amount  284807 non-null  float64\n",
            " 29  Class   284807 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('./creditcard.csv')\n",
        "df=df.drop('Time',axis=1)\n",
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a828e2f8",
      "metadata": {
        "id": "a828e2f8"
      },
      "source": [
        "PCA Transformation: The description of the data says that all the features went through a PCA transformation (Except for time and amount).  \n",
        "Scaling: Keep in mind that in order to implement a PCA transformation features need to be previously scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b13394f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "b13394f3",
        "outputId": "1209564f-7cec-4c76-8c2b-a4fcac5f36e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 V1            V2            V3            V4            V5  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15  9.604066e-16   \n",
              "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
              "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
              "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
              "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
              "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
              "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
              "\n",
              "                 V6            V7            V8            V9           V10  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15  2.239053e-15   \n",
              "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
              "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
              "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
              "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
              "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
              "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59120b11-1041-41b4-b8b6-fa794d297bc4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>2.239053e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59120b11-1041-41b4-b8b6-fa794d297bc4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59120b11-1041-41b4-b8b6-fa794d297bc4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59120b11-1041-41b4-b8b6-fa794d297bc4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7fc74c59-6b1c-40da-8d8b-482d8f372f88\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7fc74c59-6b1c-40da-8d8b-482d8f372f88')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7fc74c59-6b1c-40da-8d8b-482d8f372f88 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306b3e6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306b3e6f",
        "outputId": "3bd8d0ec-192f-4dd2-96b2-988a15aa3069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 9144 duplicate rows\n"
          ]
        }
      ],
      "source": [
        "# checking for duplicate values\n",
        "print(f\"Dataset has {df.duplicated().sum()} duplicate rows\")\n",
        "# dropping duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2f4c06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b2f4c06",
        "outputId": "4a919442-5710-4b4f-b59a-cb1a822bb06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 275663 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      275663 non-null  float64\n",
            " 1   V2      275663 non-null  float64\n",
            " 2   V3      275663 non-null  float64\n",
            " 3   V4      275663 non-null  float64\n",
            " 4   V5      275663 non-null  float64\n",
            " 5   V6      275663 non-null  float64\n",
            " 6   V7      275663 non-null  float64\n",
            " 7   V8      275663 non-null  float64\n",
            " 8   V9      275663 non-null  float64\n",
            " 9   V10     275663 non-null  float64\n",
            " 10  V11     275663 non-null  float64\n",
            " 11  V12     275663 non-null  float64\n",
            " 12  V13     275663 non-null  float64\n",
            " 13  V14     275663 non-null  float64\n",
            " 14  V15     275663 non-null  float64\n",
            " 15  V16     275663 non-null  float64\n",
            " 16  V17     275663 non-null  float64\n",
            " 17  V18     275663 non-null  float64\n",
            " 18  V19     275663 non-null  float64\n",
            " 19  V20     275663 non-null  float64\n",
            " 20  V21     275663 non-null  float64\n",
            " 21  V22     275663 non-null  float64\n",
            " 22  V23     275663 non-null  float64\n",
            " 23  V24     275663 non-null  float64\n",
            " 24  V25     275663 non-null  float64\n",
            " 25  V26     275663 non-null  float64\n",
            " 26  V27     275663 non-null  float64\n",
            " 27  V28     275663 non-null  float64\n",
            " 28  Amount  275663 non-null  float64\n",
            " 29  Class   275663 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5128908",
      "metadata": {
        "id": "c5128908"
      },
      "source": [
        "There is no null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6c996a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6c996a",
        "outputId": "9d1ab5e2-d12b-4d4b-dc25-f111484a50af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Frauds 99.83 % of the dataset\n",
            "Frauds 0.17 % of the dataset\n"
          ]
        }
      ],
      "source": [
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d88ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "d88ad047",
        "outputId": "a24c8e1b-e5a6-4ab0-bb54-532b5df49a57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Class', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(data=df,x='Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30728ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "30728ee8",
        "outputId": "d0acd070-cb87-4d40-b916-a6e41af047b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V1        -3.273070\n",
              "V2        -4.653486\n",
              "V3        -2.216730\n",
              "V4         0.681387\n",
              "V5        -2.458790\n",
              "V6         1.867576\n",
              "V7         2.877722\n",
              "V8        -8.292631\n",
              "V9         0.550965\n",
              "V10        1.242165\n",
              "V11        0.347772\n",
              "V12       -2.208171\n",
              "V13        0.061058\n",
              "V14       -1.953613\n",
              "V15       -0.295836\n",
              "V16       -1.048371\n",
              "V17       -3.802987\n",
              "V18       -0.255710\n",
              "V19        0.115957\n",
              "V20       -2.045060\n",
              "V21        2.784302\n",
              "V22       -0.200868\n",
              "V23       -5.805236\n",
              "V24       -0.545636\n",
              "V25       -0.408260\n",
              "V26        0.587603\n",
              "V27       -0.745732\n",
              "V28       11.400938\n",
              "Amount    16.841622\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>-3.273070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>-4.653486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>-2.216730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0.681387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>-2.458790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>1.867576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>2.877722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>-8.292631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0.550965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>1.242165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0.347772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>-2.208171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0.061058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>-1.953613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>-0.295836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>-1.048371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>-3.802987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>-0.255710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0.115957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>-2.045060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>2.784302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>-0.200868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>-5.805236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>-0.545636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>-0.408260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0.587603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>-0.745732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>11.400938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <td>16.841622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.drop('Class',axis=1).skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85bb3774",
      "metadata": {
        "id": "85bb3774"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab1142e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ab1142e",
        "outputId": "eb5808bc-933f-47ee-afbb-96f6903f22cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(275663, 29) (275663,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df.drop('Class', axis=1))\n",
        "y = df['Class'].values\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e31517",
      "metadata": {
        "id": "22e31517"
      },
      "source": [
        "## Splitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa74b00",
      "metadata": {
        "id": "6fa74b00"
      },
      "source": [
        "we want to test our models on the original testing set not on the testing set created from GAN. The main goal is to fit the model in the generated data, and test it on the original testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8303d35",
      "metadata": {
        "id": "f8303d35"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50b98b70",
      "metadata": {
        "id": "50b98b70"
      },
      "source": [
        "## Conditional GAN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, multiply, LeakyReLU, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class cGAN():\n",
        "    def __init__(self):\n",
        "        self.latent_dim = 32\n",
        "        self.out_shape = 29\n",
        "        self.num_classes = 2\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,))\n",
        "        gen_samples = self.generator([noise, label])\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator([gen_samples, label])\n",
        "\n",
        "        self.combined = Model([noise, label], valid)\n",
        "        self.combined.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(0.0002, 0.5),\n",
        "                              metrics=['accuracy'])\n",
        "        self.combined.summary()\n",
        "\n",
        "    def build_generator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(self.out_shape, activation='tanh'))\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
        "        model_input = multiply([noise, label_embedding])\n",
        "        gen_sample = model(model_input)\n",
        "\n",
        "        return Model([noise, label], gen_sample, name=\"Generator\")\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(GaussianNoise(0.1, input_shape=(self.out_shape,)))\n",
        "        model.add(Dense(256, kernel_initializer=init, kernel_regularizer=l2(0.001)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        gen_sample = Input(shape=(self.out_shape,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.out_shape)(label))\n",
        "        model_input = multiply([gen_sample, label_embedding])\n",
        "        validity = model(model_input)\n",
        "\n",
        "        return Model([gen_sample, label], validity, name=\"Discriminator\")\n",
        "\n",
        "    def train(self, X_train, y_train, pos_index, neg_index, epochs, batch_size=32, sample_interval=50):\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # === Train Discriminator ===\n",
        "            idx1 = np.random.choice(pos_index, 8)\n",
        "            idx0 = np.random.choice(neg_index, batch_size - 8)\n",
        "            idx = np.concatenate((idx1, idx0))\n",
        "            samples, labels = X_train[idx], y_train[idx]\n",
        "            samples, labels = shuffle(samples, labels)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_samples = self.generator.predict([noise, labels], verbose=0)\n",
        "\n",
        "            valid_smooth = np.random.uniform(low=0.9, high=1.0, size=(batch_size, 1))\n",
        "            fake_smooth = np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
        "\n",
        "            if np.random.rand() < 0.05:\n",
        "                valid_smooth, fake_smooth = fake_smooth, valid_smooth\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "            d_loss_real = self.discriminator.train_on_batch([samples, labels], valid_smooth)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([gen_samples, labels], fake_smooth)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # === Train Generator ===\n",
        "            self.discriminator.trainable = False\n",
        "            sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
        "\n",
        "\n",
        "            if (epoch + 1) % sample_interval == 0:\n",
        "                print(f\"{epoch + 1} [D loss: {d_loss[0]:.4f}, acc: {100*d_loss[1]:.2f}%] \"\n",
        "                      f\"[G loss: {g_loss[0]:.4f}, acc: {100*g_loss[1]:.2f}%]\")\n",
        "\n",
        "                d_real_pred = self.discriminator.predict([samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                d_fake_pred = self.discriminator.predict([gen_samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                print(\"Disc pred on real:\", np.round(d_real_pred, 2))\n",
        "                print(\"Disc pred on fake:\", np.round(d_fake_pred, 2))\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                self.save_generated_samples(epoch + 1)\n",
        "\n",
        "    def save_generated_samples(self, epoch):\n",
        "        noise = np.random.normal(0, 1, (5, self.latent_dim))\n",
        "        labels = np.array([[0], [1], [0], [1], [1]])\n",
        "        gen_samples = self.generator.predict([noise, labels])\n",
        "        print(f\"Generated samples at epoch {epoch}:\\n{gen_samples}\")"
      ],
      "metadata": {
        "id": "zL2u47WRNTOr"
      },
      "id": "zL2u47WRNTOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d2d7879",
      "metadata": {
        "id": "2d2d7879"
      },
      "source": [
        "## Training GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def experiment_1_scaling_gan_lgbm(GAN_class, X_train, y_train, X_test, y_test, scaler, epochs=300, latent_dim=32):\n",
        "\n",
        "    fraud_data = X_train[y_train.ravel() == 1]\n",
        "    nonfraud_data = X_train[y_train.ravel() == 0]\n",
        "\n",
        "    sizes = [0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "    results = []\n",
        "\n",
        "    for frac in tqdm(sizes, desc=\"Experiment 1 (LGBM) Loop\"):\n",
        "        sample_size = int(len(fraud_data) * frac)\n",
        "        fraud_subset = fraud_data[:sample_size]\n",
        "\n",
        "        # Combine with all non-fraud data\n",
        "        combined_X = np.vstack([fraud_subset, nonfraud_data])\n",
        "        combined_y = np.vstack([\n",
        "            np.ones((sample_size, 1)),\n",
        "            np.zeros((len(nonfraud_data), 1))\n",
        "        ])\n",
        "\n",
        "        idx_pos = np.where(combined_y == 1)[0]\n",
        "        idx_neg = np.where(combined_y == 0)[0]\n",
        "\n",
        "\n",
        "        gan = GAN_class()\n",
        "        gan.train(combined_X, combined_y, idx_pos, idx_neg, epochs=epochs, batch_size=64)\n",
        "\n",
        "        # Generate synthetic fraud samples\n",
        "        noise = np.random.normal(0, 1, (25000, latent_dim))\n",
        "\n",
        "        gen_labels = np.ones((25000, 1))\n",
        "        gen_samples = gan.generator.predict([noise, gen_labels], verbose=0)\n",
        "\n",
        "\n",
        "        aug_X = np.vstack([X_train, gen_samples])\n",
        "        # Reshape y_train to be 2D before stacking\n",
        "        aug_y = np.vstack([y_train.reshape(-1, 1), np.ones((25000, 1))]).ravel()\n",
        "\n",
        "        # Train LGBMClassifier\n",
        "        clf = LGBMClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            class_weight='balanced',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        clf.fit(aug_X, aug_y)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        roc = roc_auc_score(y_test, y_prob)\n",
        "        pr = average_precision_score(y_test, y_prob)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        results.append((int(frac * 100), roc, pr, f1))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "sEpb9XQMcPV2"
      },
      "id": "sEpb9XQMcPV2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_experiment_1(results):\n",
        "    import matplotlib.pyplot as plt\n",
        "    x = [r[0] for r in results]\n",
        "    roc = [r[1] for r in results]\n",
        "    pr = [r[2] for r in results]\n",
        "    f1 = [r[3] for r in results]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, roc, label=\"ROC-AUC\", marker='o')\n",
        "    plt.plot(x, pr, label=\"PR-AUC\", marker='s')\n",
        "    plt.plot(x, f1, label=\"F1-score\", marker='^')\n",
        "    plt.xlabel(\"Fraud Training Set Size (%)\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(\"Experiment 1: Model Performance vs GAN Training Size\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "H9xs58f5cABu"
      },
      "id": "H9xs58f5cABu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the cGAN class\n",
        "cgan_model = cGAN()\n",
        "\n",
        "# Fix the function call to pass the cGAN class\n",
        "results = experiment_1_scaling_gan_lgbm(cGAN, X_train, y_train, X_test, y_test, scaler)\n",
        "plot_experiment_1(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_p_fwkLrb_2L",
        "outputId": "3371c02a-6601-47c6-d777-8c1aa14a1a4b"
      },
      "id": "_p_fwkLrb_2L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_13 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_14 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_15 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_30      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_31      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_30[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_31[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_31[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_30      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_31      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 (LGBM) Loop:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_4                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_24 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_16 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_25 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_4                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_26 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_17 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_27 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_18 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_19 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_89\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_89\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_38      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_39      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_38[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_39[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_39[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_38      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_39      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6946, acc: 0.00%] [G loss: 0.6872, acc: 70.84%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6924, acc: 0.00%] [G loss: 0.6824, acc: 71.09%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.61 0.5 ]\n",
            "Disc pred on fake: [0.5  0.49 0.51 0.53 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.9423464   0.9527638   0.7744985   0.94674444 -0.27406812  0.9741804\n",
            "  -0.83038455 -0.99888074  0.99564844  0.96953166  0.20295142  0.9997762\n",
            "   0.22501777 -0.9848269  -0.93411195  0.9980173   0.9993195   0.57538366\n",
            "  -0.99990445 -0.58909196 -0.86287487  0.73766214 -0.5973538   0.9970629\n",
            "  -0.6266651   0.99347454 -0.9532327  -0.9476551   0.12648942]\n",
            " [-0.9415868   0.8742186  -0.91380024  0.96784085 -0.8062924  -0.993167\n",
            "   0.42926383  0.9978573  -0.9975454  -0.9546199   0.989741   -0.9996025\n",
            "   0.874622   -0.978797   -0.24565865 -0.99664867 -0.97522146 -0.9923379\n",
            "   0.5717923   0.700276    0.6310964   0.86644983  0.6744729  -0.8406786\n",
            "   0.08681507 -0.15831564  0.9603088   0.9501383  -0.8030215 ]\n",
            " [ 0.534602   -0.6636883   0.8234633   0.99969417 -0.9978772   0.7834065\n",
            "  -0.20040238 -0.94241834  0.9266155   0.9731172  -0.96322674  0.990395\n",
            "  -0.7535725  -0.7404506  -0.99662226  0.9952469  -0.741955    0.812183\n",
            "   0.8970903  -0.9811818   0.23008348  0.8871139  -0.42547986  0.9530121\n",
            "   0.04215021  0.70495296 -0.99863946  0.9951615   0.9925765 ]\n",
            " [-0.9181105   0.9115091  -0.8553328   0.9082031  -0.7874387  -0.9896167\n",
            "   0.2777971   0.9980913  -0.99773765 -0.9521453   0.9919703  -0.99929357\n",
            "   0.75392705 -0.9824545  -0.3624362  -0.9966493  -0.9752292  -0.9872859\n",
            "   0.38372245  0.72695404  0.4453292   0.8457681   0.8281901  -0.7646626\n",
            "  -0.09410091 -0.19986565  0.9031977   0.8995239  -0.60394317]\n",
            " [-0.95339406  0.8041284  -0.8542767   0.92691255 -0.67516845 -0.98483884\n",
            "   0.44810304  0.9987938  -0.9977809  -0.9393746   0.9919839  -0.9994286\n",
            "   0.88502944 -0.977485    0.06796502 -0.9979212  -0.9548254  -0.98961\n",
            "   0.69048154  0.5206718   0.58933944  0.90413374  0.6743399  -0.6609311\n",
            "  -0.22634375 -0.08639383  0.9285606   0.9385077  -0.74182993]]\n",
            "150 [D loss: 0.6901, acc: 0.00%] [G loss: 0.6753, acc: 70.79%]\n",
            "Disc pred on real: [0.5  0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.49 0.52 0.52 0.47 0.52]\n",
            "200 [D loss: 0.6889, acc: 0.00%] [G loss: 0.6694, acc: 71.88%]\n",
            "Disc pred on real: [0.49 0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.49 0.5  0.5  0.49 0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.9725448   0.84609395 -0.99998635  0.9276433   0.8114144  -0.8462888\n",
            "  -0.2987248   0.91408134 -0.7327905  -0.9635884   0.9995381  -0.97086227\n",
            "   0.95628506 -0.95336664  0.9504256  -0.9476718  -0.9892736  -0.9471812\n",
            "   0.20149432 -0.21028966 -0.6281017  -0.14564675 -0.07967716  0.64708906\n",
            "   0.6683881  -0.50760365  0.92100835  0.458883    0.16700679]\n",
            " [-0.72313744 -0.9487117  -0.35563698  0.96975595 -0.00873184  0.9663352\n",
            "  -0.9802134  -0.98180115 -0.9645171  -0.9895341   0.99045026 -0.991908\n",
            "   0.837522   -0.998098    0.72081465 -0.99181765 -0.99705106 -0.96918565\n",
            "   0.12538308 -0.48960844  0.5754789  -0.77886695  0.87710893 -0.07177695\n",
            "  -0.29341322 -0.14824818 -0.13424046 -0.75353587  0.20554627]\n",
            " [ 0.20161293 -0.4644297  -0.9858692   0.9942782  -0.9300344  -0.6009833\n",
            "  -0.4137392   0.8274381  -0.05203146  0.9813002   0.972413   -0.2811596\n",
            "  -0.62334955  0.57630223 -0.21611133 -0.68702483 -0.00385876 -0.50703055\n",
            "   0.6943954  -0.62035143 -0.9921688  -0.62095433 -0.24248748 -0.5639875\n",
            "  -0.52294946 -0.21379739 -0.37786308  0.2324176   0.6535436 ]\n",
            " [-0.71584547 -0.95058733 -0.33543018  0.97187334  0.00274501  0.97222894\n",
            "  -0.98044217 -0.98157775 -0.96074283 -0.98840344  0.9907356  -0.99266255\n",
            "   0.8376048  -0.998255    0.7224901  -0.9918044  -0.9966308  -0.96909857\n",
            "   0.16475323 -0.45262438  0.5371753  -0.7657209   0.89146835 -0.03397352\n",
            "  -0.31588936 -0.13668437 -0.18211325 -0.7558067   0.2705226 ]\n",
            " [-0.700901   -0.949819   -0.35476872  0.97046196 -0.02857674  0.9679677\n",
            "  -0.9814587  -0.9790703  -0.96143997 -0.98856604  0.9908476  -0.9912461\n",
            "   0.8480549  -0.99823505  0.72406065 -0.9918935  -0.99674267 -0.96916366\n",
            "   0.14492188 -0.45212573  0.5247967  -0.7818877   0.88024503 -0.05589361\n",
            "  -0.25338423 -0.13528815 -0.16182646 -0.7478271   0.23812118]]\n",
            "250 [D loss: 0.6873, acc: 0.00%] [G loss: 0.6661, acc: 71.24%]\n",
            "Disc pred on real: [0.49 0.49 0.49 0.49 0.49]\n",
            "Disc pred on fake: [0.49 0.5  0.49 0.5  0.49]\n",
            "300 [D loss: 0.6859, acc: 0.00%] [G loss: 0.6643, acc: 70.16%]\n",
            "Disc pred on real: [0.5  0.49 0.48 0.77 0.49]\n",
            "Disc pred on fake: [0.49 0.49 0.49 0.55 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.93422765 -0.90433216 -0.98550117  0.9997438  -0.99209535 -0.71110046\n",
            "  -0.18201129 -0.891452   -0.77926224 -0.9956394   0.99980104 -0.98449826\n",
            "  -0.26304963  0.0069994   0.96439725 -0.998515   -0.7566685  -0.95315033\n",
            "   0.3623326  -0.9841404  -0.7294237  -0.639725    0.04981415  0.14743075\n",
            "   0.90336615 -0.68449974  0.9995012   0.9372484  -0.27021158]\n",
            " [-0.44074818  0.9995394  -0.97860813  0.9957955  -0.2931663   0.90437865\n",
            "  -0.95100605 -0.89384425  0.9157345  -0.9976562   0.9952702  -0.99909914\n",
            "  -0.11812704 -0.99998134 -0.9032132  -0.9992209  -0.99998546  0.8837873\n",
            "   0.9502859   0.9351183   0.8585562   0.8109365  -0.51251334 -0.8755271\n",
            "   0.74282813 -0.6845458  -0.47419325  0.9055863  -0.7964655 ]\n",
            " [-0.9187291  -0.44410285 -0.98701555 -0.9715217   0.7291182  -0.9189557\n",
            "   0.86862487 -0.93754166 -0.9955976  -0.9972073   0.9658538  -0.9969605\n",
            "  -0.21346289  0.99461925  0.9965659  -0.99937284 -0.96210015 -0.76196843\n",
            "  -0.61425376 -0.63420504 -0.98440874 -0.25962695  0.8501085  -0.9115446\n",
            "   0.85101175 -0.9668353   0.9999455  -0.7346428  -0.69174075]\n",
            " [-0.40566772  0.99948436 -0.9697694   0.9955314  -0.36669716  0.8985123\n",
            "  -0.9504307  -0.8979852   0.911512   -0.9977786   0.994913   -0.9990649\n",
            "  -0.03698198 -0.9999792  -0.89290875 -0.99916774 -0.99998665  0.85954434\n",
            "   0.95239747  0.94143873  0.8470043   0.8337359  -0.47253194 -0.87748986\n",
            "   0.7462172  -0.66743255 -0.43215102  0.90202886 -0.73842376]\n",
            " [-0.4417245   0.9994768  -0.96949124  0.9950697  -0.3809327   0.87714195\n",
            "  -0.9500996  -0.90478206  0.9009081  -0.9979084   0.99566174 -0.9990969\n",
            "  -0.0807365  -0.99997735 -0.8930446  -0.99919456 -0.99998647  0.86464804\n",
            "   0.9510329   0.9352278   0.8557302   0.8115618  -0.50452095 -0.8580001\n",
            "   0.7494773  -0.67288566 -0.38991255  0.89581114 -0.7634706 ]]\n",
            "[LightGBM] [Info] Number of positive: 25378, number of negative: 220152\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076672 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 245530, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "Experiment 1 (LGBM) Loop:  20%|â–ˆâ–ˆ        | 1/5 [02:18<09:15, 138.86s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_5                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_20 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_5                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_32 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_21 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_33 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_22 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_34 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_23 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_35 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_107\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_107\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_46      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_47      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_46[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_47[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_47[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_46      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_47      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6936, acc: 0.00%] [G loss: 0.6945, acc: 42.50%]\n",
            "Disc pred on real: [0.5  0.5  0.66 0.49 0.5 ]\n",
            "Disc pred on fake: [0.5  0.5  0.51 0.5  0.5 ]\n",
            "100 [D loss: 0.6911, acc: 0.00%] [G loss: 0.6920, acc: 48.05%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.49 0.5 ]\n",
            "Disc pred on fake: [0.5  0.48 0.51 0.49 0.51]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[-0.60491157  0.71401674  0.33492047 -0.696313    0.9332496  -0.30811197\n",
            "   0.05941415 -0.00982938  0.45887905  0.8589068   0.7254394   0.7720105\n",
            "   0.6523732  -0.34561178  0.4581076   0.33235145  0.9468272  -0.01760173\n",
            "  -0.88744265  0.39292035 -0.889546    0.46906412  0.7693578  -0.70885533\n",
            "   0.8414197  -0.40852824  0.6914575   0.17773798  0.5853329 ]\n",
            " [ 0.82725585 -0.05610859 -0.93977714 -0.20939097 -0.595977   -0.96944654\n",
            "  -0.96787375 -0.6856518  -0.09818552  0.35178417 -0.53552157 -0.7199982\n",
            "  -0.9975894  -0.97532094 -0.10622501  0.45221    -0.99755883  0.49333328\n",
            "  -0.2618083   0.4709721   0.60500306  0.94337076  0.7049341   0.25269902\n",
            "  -0.853112   -0.7999601   0.69478774  0.73281485  0.93813515]\n",
            " [-0.45429376 -0.7894703   0.10166463 -0.31631437  0.73177695 -0.7901804\n",
            "  -0.81099653 -0.23822908 -0.4661618  -0.2736217  -0.78533244  0.09041143\n",
            "   0.2591353  -0.67574155 -0.55618006 -0.74059856 -0.95102775 -0.89593744\n",
            "  -0.88293326  0.679338   -0.7441715   0.66916037 -0.79773736  0.4303957\n",
            "   0.68340117 -0.00290255 -0.19732544  0.5901421   0.8004136 ]\n",
            " [-0.5664635   0.8242981   0.22351627  0.9761856  -0.97116786 -0.7416712\n",
            "  -0.04357931  0.46582437 -0.02349169 -0.4646797   0.6509415  -0.2359915\n",
            "   0.3058434  -0.7995966  -0.2579421   0.9118283  -0.8314346  -0.62226903\n",
            "   0.7632564  -0.95590043  0.9512186  -0.85298896  0.1511319   0.9104403\n",
            "   0.88642645 -0.6155214  -0.7444732   0.9610281  -0.9800203 ]\n",
            " [-0.05121397  0.11833531 -0.57133573  0.55357134 -0.92733985  0.6997453\n",
            "  -0.59225607  0.9634786  -0.92327654 -0.31186193 -0.9973964  -0.1759464\n",
            "   0.7209943  -0.7146393  -0.00821939  0.00896723 -0.910703   -0.56926256\n",
            "   0.627718    0.90438956  0.8055577  -0.9222793   0.82815987 -0.948077\n",
            "  -0.82998437 -0.5196427  -0.8156244   0.47039333  0.61379904]]\n",
            "150 [D loss: 0.6898, acc: 0.00%] [G loss: 0.6886, acc: 53.04%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.48 0.51 0.52 0.5  0.47]\n",
            "200 [D loss: 0.6894, acc: 0.00%] [G loss: 0.6840, acc: 58.36%]\n",
            "Disc pred on real: [0.5  0.49 0.49 0.49 0.47]\n",
            "Disc pred on fake: [0.51 0.51 0.51 0.53 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[ 0.46450576 -1.         -0.99999297 -1.          1.         -0.71263564\n",
            "   1.          0.18427216  0.99999946  1.         -0.98849857  0.09058645\n",
            "  -0.57125586  1.         -0.45158732  1.          1.         -0.98293495\n",
            "  -1.         -0.9944705  -1.         -0.990865   -0.98515546  0.7970381\n",
            "  -0.9935821  -0.95785284  0.6196279   0.92877066  0.9995604 ]\n",
            " [-0.24650928  0.7450915   0.74680555  0.94533694 -0.91128314  0.61064166\n",
            "  -0.9742715   0.13249941 -0.99406064 -0.98568875  0.8318139  -0.8759782\n",
            "   0.87257326 -0.98179024  0.8832386  -0.9833341  -0.98589337  0.916025\n",
            "   0.9592727   0.6809158   0.9441014   0.005943   -0.86450464  0.8981037\n",
            "   0.2894676   0.31984195 -0.6418109  -0.5287075   0.12835112]\n",
            " [ 0.34509242  0.9810632   0.9994844   0.9747693  -0.887411    0.01002073\n",
            "  -0.9576452  -0.45791984 -0.9390962  -0.9309488  -0.02579677 -0.5012358\n",
            "  -0.69716734 -0.9724732   0.66387486 -0.9144285  -0.9404005   0.98936254\n",
            "   0.9837684  -0.09580937  0.9745381  -0.8202998   0.56327486 -0.68390185\n",
            "   0.85434616 -0.41689163 -0.04822285  0.41979524 -0.7331756 ]\n",
            " [ 0.03388451  0.8493038  -0.1621045   0.9931069  -0.9530003  -0.9575669\n",
            "  -0.9688598   0.23763494 -0.90968615 -0.9278991  -0.83143944 -0.8261891\n",
            "   0.9332386  -0.9715725  -0.20776817 -0.9420724  -0.99323654  0.21907432\n",
            "   0.9457378   0.78945875  0.9855602  -0.02450993  0.32731315 -0.50633603\n",
            "   0.80781174 -0.85745835  0.52524483 -0.2748578  -0.4956698 ]\n",
            " [ 0.04216416  0.7583039  -0.65136     0.9940496  -0.94481325  0.9960489\n",
            "  -0.9910225  -0.10854557 -0.97858393 -0.9937369   0.10983077 -0.94781566\n",
            "   0.8033084  -0.9997778  -0.56163406 -0.97287875 -0.99732    -0.37658867\n",
            "   0.9246614   0.8746523   0.9840706  -0.21314676 -0.28623533 -0.9265374\n",
            "   0.20912099 -0.54569024  0.78129375 -0.6809375  -0.38443676]]\n",
            "250 [D loss: 0.6879, acc: 0.00%] [G loss: 0.6807, acc: 61.71%]\n",
            "Disc pred on real: [0.5  0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.5  0.49 0.5  0.5  0.5 ]\n",
            "300 [D loss: 0.6873, acc: 0.00%] [G loss: 0.6787, acc: 63.02%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.49 0.5  0.5  0.49 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[ 0.21193062  0.75965774 -0.41740686  0.73780304 -0.99437624 -0.8303644\n",
            "  -0.9144665   0.092338   -0.98875195 -0.80640316  0.3692204  -0.9302816\n",
            "   0.92731446 -0.9189335  -0.721625   -0.8341702  -0.9865487  -0.63671905\n",
            "   0.8969073   0.9887797   0.6306257  -0.9868917   0.43469298  0.327301\n",
            "   0.5109063  -0.6880469   0.8636603   0.6937627   0.17200099]\n",
            " [-0.8868023   0.78211194 -0.9852723   0.74126345  0.733603    0.9158678\n",
            "  -0.991744    0.60116035 -0.50231826 -0.9943449  -0.13037801 -0.993322\n",
            "   0.9270223  -0.996416    0.66077584 -0.991462   -0.9950153  -0.9630774\n",
            "   0.97954684  0.9656588  -0.2588917  -0.26077002  0.6128301   0.56469774\n",
            "   0.65058196 -0.12525682 -0.06369811  0.8417595  -0.94902104]\n",
            " [ 0.6029063   0.90171695  0.8907454   0.97027886 -0.99904835 -0.7418048\n",
            "  -0.07661364  0.997026   -0.9995146   0.98549765 -0.7824816  -0.05690311\n",
            "   0.85343623  0.9984638  -0.9219928   0.9658784   0.9809617   0.9545771\n",
            "  -0.420519   -0.6983946   0.99933773  0.9276813  -0.76697665 -0.2926738\n",
            "  -0.20351578  0.5732034   0.71479475 -0.1095888   0.97143877]\n",
            " [-0.91263837  0.9402237  -0.8928041   0.84019536  0.68857557  0.01516147\n",
            "  -0.93610424 -0.91458106 -0.7166986  -0.995316    0.79684854 -0.98199236\n",
            "   0.8156989  -0.9979305   0.65060496 -0.99708736 -0.98895717 -0.99092484\n",
            "   0.64576143  0.04005558  0.9019291   0.4703898   0.08340295  0.77732086\n",
            "  -0.1757991   0.23536079  0.54407364  0.20997833 -0.55889964]\n",
            " [-0.86558914  0.7881353  -0.83997047  0.9883839  -0.00428086  0.06717624\n",
            "  -0.9800675  -0.3711436  -0.9352481  -0.99875647  0.81087744 -0.9745644\n",
            "   0.53440297 -0.99953043  0.0935429  -0.9945745  -0.9988917  -0.9728586\n",
            "   0.59737206 -0.3609912   0.92249846  0.6011534  -0.9147082   0.87244636\n",
            "  -0.33984402 -0.08104291 -0.39196402  0.8458872  -0.6974546 ]]\n",
            "[LightGBM] [Info] Number of positive: 25378, number of negative: 220152\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 245530, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "Experiment 1 (LGBM) Loop:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [04:41<07:03, 141.06s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_6                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_24 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_6                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_38 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_25 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_39 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_26 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_40 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_27 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_41 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_125\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_125\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_54      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_55      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_54[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_55[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_55[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_54      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_55      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6934, acc: 0.00%] [G loss: 0.6893, acc: 65.31%]\n",
            "Disc pred on real: [0.54 0.5  0.5  0.57 0.5 ]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6885, acc: 0.00%] [G loss: 0.6872, acc: 62.75%]\n",
            "Disc pred on real: [0.73 0.51 0.49 0.5  0.49]\n",
            "Disc pred on fake: [0.53 0.48 0.52 0.49 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.6598167  -0.8529762   0.8332927   0.8303442   0.3664764  -0.69905037\n",
            "   0.95970094  0.5145456   0.96600085 -0.62564117 -0.8537317  -0.5750939\n",
            "   0.84866315 -0.7733946   0.00154009 -0.0666724  -0.52242893  0.5383008\n",
            "  -0.1607767  -0.85700196 -0.17253138 -0.70335     0.07797401  0.81923884\n",
            "   0.666822    0.7133617  -0.26016584  0.90048563 -0.57527924]\n",
            " [-0.97030467  0.8946144  -0.9600415  -0.42904165 -0.8135516  -0.5897437\n",
            "  -0.9739415  -0.9428566  -0.9952382   0.30844522  0.99522686 -0.40164095\n",
            "   0.00756196 -0.26307294 -0.5188012   0.9480581   0.11084832  0.9327292\n",
            "   0.9990891   0.8979206  -0.9994427  -0.57838285  0.41537863 -0.99404705\n",
            "  -0.93462604  0.01455466 -0.57133394  0.87217134  0.7905903 ]\n",
            " [ 0.92174745  0.33704615  0.87971604  0.95307237 -0.60596925 -0.8817701\n",
            "   0.97629374  0.49106959  0.96741384  0.60515106 -0.97198343  0.41869646\n",
            "  -0.00149772 -0.3697057   0.23041567 -0.59186316 -0.621747    0.6099744\n",
            "  -0.5068264  -0.01052038  0.81018114 -0.5918532   0.45780572  0.9047905\n",
            "   0.9678397   0.7090104   0.07967044  0.7953508  -0.09084153]\n",
            " [ 0.9538518  -0.33666873 -0.17937861  0.9736128  -0.51719874  0.29154608\n",
            "   0.65180063  0.45179418  0.47418347 -0.4731148   0.09317806  0.16125347\n",
            "   0.51790243 -0.92013633  0.5901972   0.62883955 -0.8935659   0.21109545\n",
            "  -0.0687339   0.4875097  -0.5428251  -0.27511814  0.7056168  -0.44581378\n",
            "   0.6486715   0.7942454   0.34135643  0.876001   -0.31333917]\n",
            " [ 0.94777334  0.4867107  -0.33719814  0.98092043  0.912929   -0.78037196\n",
            "  -0.9977834   0.46853343 -0.69013333 -0.98106676 -0.02149799  0.0864832\n",
            "  -0.15566114 -0.91480756 -0.49550563  0.9776863  -0.9513623  -0.99013084\n",
            "  -0.394073    0.7218684   0.84598345 -0.89355046  0.4148769  -0.90106714\n",
            "   0.8937683  -0.5033397   0.99418366 -0.7455149  -0.65485424]]\n",
            "150 [D loss: 0.6875, acc: 0.00%] [G loss: 0.6811, acc: 65.29%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.49 0.69]\n",
            "Disc pred on fake: [0.52 0.47 0.47 0.52 0.54]\n",
            "200 [D loss: 0.6871, acc: 0.00%] [G loss: 0.6768, acc: 68.08%]\n",
            "Disc pred on real: [0.5  0.61 0.5  0.77 0.64]\n",
            "Disc pred on fake: [0.48 0.53 0.51 0.53 0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.97288847 -0.1490808  -0.9872502   0.9964614   0.0310419  -0.69713867\n",
            "  -0.9974958   0.3934994  -0.94634664 -0.99772334  0.99004227 -0.9925924\n",
            "  -0.89556324 -0.99280155  0.8025402  -0.9399904  -0.9885373  -0.9005825\n",
            "   0.88880247  0.5599895   0.75362664 -0.67328745 -0.98202145 -0.09551591\n",
            "  -0.29918036  0.9466294   0.9038369  -0.8464371  -0.6158457 ]\n",
            " [-0.9970662  -0.8621553  -0.98633003  0.97916013  0.78665274 -0.7927823\n",
            "  -0.9983957   0.50557387 -0.95382744 -0.9981999   0.9770165  -0.9977865\n",
            "  -0.64730597 -0.999157    0.91195285 -0.17695452 -0.99546975 -0.96839905\n",
            "   0.83795685  0.10360105  0.8150761   0.6462752  -0.8320873   0.7563225\n",
            "   0.953132   -0.906257    0.03469345  0.8694308  -0.68930787]\n",
            " [-0.9832745  -0.9981511  -0.98550797  0.94375205  0.57657605  0.27166253\n",
            "  -0.9624818   0.1872823  -0.968611   -0.96954924  0.9684654  -0.9573607\n",
            "  -0.2548217  -0.9755136   0.13623568 -0.9927364  -0.94941676 -0.91230935\n",
            "   0.9734725  -0.33941233  0.8191343   0.8774521  -0.8453732   0.8711633\n",
            "  -0.9933323  -0.9781267   0.7174704  -0.27843127 -0.38664487]\n",
            " [-0.80714226  0.8774825  -0.9785878   0.982493    0.55775905  0.42100787\n",
            "  -0.9987704  -0.02249714 -0.9893178  -0.9959699   0.9634035  -0.99909097\n",
            "  -0.19510435 -0.9996     -0.03627907 -0.97809815 -0.9989959  -0.9829599\n",
            "   0.9810973   0.54656273 -0.14383148  0.9140114  -0.94068074  0.6473852\n",
            "   0.5117943   0.96051013  0.64981127 -0.29899472 -0.63494945]\n",
            " [-0.97925925  0.48833317 -0.9922463   0.9701747  -0.70643115 -0.29844847\n",
            "  -0.9833636  -0.60397285 -0.9581014  -0.98553026  0.9919863  -0.9865776\n",
            "  -0.2667388  -0.99800694  0.55178225 -0.44113398 -0.9898848  -0.956086\n",
            "   0.91080487  0.81842816  0.9298594  -0.99323577 -0.21075407  0.8127075\n",
            "  -0.31074187  0.38465673  0.6818569  -0.9448388   0.10359296]]\n",
            "250 [D loss: 0.6866, acc: 0.00%] [G loss: 0.6760, acc: 68.94%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.49 0.49]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "300 [D loss: 0.6858, acc: 0.00%] [G loss: 0.6756, acc: 68.28%]\n",
            "Disc pred on real: [0.78 0.49 0.5  0.49 0.49]\n",
            "Disc pred on fake: [0.52 0.5  0.49 0.49 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.99681205  0.07621922 -0.62101334  0.90305436  0.9134944  -0.26406318\n",
            "  -0.80856806  0.96288425  0.968982   -0.50007623  0.99924344 -0.4142357\n",
            "   0.44835383  0.23927735  0.95008975 -0.9060839   0.07081927 -0.8414363\n",
            "  -0.565996   -0.82393503 -0.6341106  -0.228258   -0.5080337   0.91616786\n",
            "   0.6879851   0.2318018  -0.90920615  0.988927   -0.45449355]\n",
            " [ 0.74542063  0.89060843 -0.72457844  0.7948033  -0.50738734  0.04149529\n",
            "  -0.9930004  -0.74914914 -0.8291862  -0.9923783  -0.85022306 -0.9965302\n",
            "   0.18777518 -0.99753743 -0.19338956 -0.49405974 -0.9974087   0.5658443\n",
            "   0.91484666  0.68989927 -0.7471901   0.9631841   0.6335795  -0.05757608\n",
            "   0.9116917  -0.10527156 -0.79735386  0.07992449 -0.9459186 ]\n",
            " [-0.52225566  0.8868095  -0.7661243   0.99303865 -0.12655501 -0.84470147\n",
            "  -0.978792    0.02154756 -0.9602673  -0.99548745  0.97609437 -0.983059\n",
            "  -0.6844126  -0.98491454  0.90063167  0.04907529 -0.9928931  -0.26212838\n",
            "   0.51073366  0.83466667  0.7636206  -0.2578055   0.66600716  0.5785911\n",
            "   0.9732575   0.87117916  0.6041917  -0.0265122  -0.3472182 ]\n",
            " [ 0.07569993  0.6688526  -0.8039862   0.9619899  -0.886936   -0.53938746\n",
            "  -0.98273146 -0.8588451  -0.7427685  -0.9970589  -0.40013957 -0.9900795\n",
            "  -0.2909105  -0.9921426   0.2651437   0.8790536  -0.98997635 -0.4650153\n",
            "   0.9773201   0.9906893   0.9600168  -0.9009151   0.8882889   0.71815723\n",
            "   0.9137403   0.9560743   0.19582479  0.22589126 -0.60620505]\n",
            " [ 0.8802869   0.6646078  -0.5550915   0.7988403  -0.992103   -0.6564662\n",
            "  -0.99233305 -0.5918827  -0.7310733  -0.9923876  -0.68257636 -0.9963986\n",
            "   0.4797719  -0.99314374  0.4307967   0.82075703 -0.9919796  -0.03735813\n",
            "   0.9801616   0.953511    0.8797977   0.05488782  0.8731536   0.07916236\n",
            "   0.958514    0.97424024 -0.6396684   0.6805944  -0.34973451]]\n",
            "[LightGBM] [Info] Number of positive: 25378, number of negative: 220152\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089692 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 245530, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "Experiment 1 (LGBM) Loop:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [07:03<04:43, 141.64s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_7                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_42 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_28 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_43 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_7                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_44 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_29 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_21          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_45 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_30 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_22          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_46 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_31 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_23          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_47 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_21          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_22          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_23          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_143\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_143\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_62      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_63      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_62[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_63[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_63[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_62      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_63      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6938, acc: 0.00%] [G loss: 0.6924, acc: 50.38%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.5  0.51 0.5  0.5  0.5 ]\n",
            "100 [D loss: 0.6899, acc: 0.00%] [G loss: 0.6892, acc: 53.78%]\n",
            "Disc pred on real: [0.5  0.65 0.5  0.49 0.5 ]\n",
            "Disc pred on fake: [0.47 0.52 0.48 0.48 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.9962593   0.72420317 -0.28070825  0.5109514   0.17585842  0.99409866\n",
            "   0.9912373   0.3065655  -0.34760448  0.25539324  0.2967173   0.3917053\n",
            "   0.8522785   0.8891651   0.35696438  0.92000157  0.98981684  0.97312057\n",
            "   0.75361717  0.4757051  -0.41757724  0.56827897  0.69736683  0.1759159\n",
            "  -0.6598681   0.86651105  0.8461572  -0.90585953 -0.03054315]\n",
            " [-0.99419934 -0.02101958 -0.98653126  0.9924456  -0.99586195 -0.9998878\n",
            "  -0.99945664 -0.95635974 -0.72224724 -0.9841304   0.9922412  -0.87952584\n",
            "  -0.76043546 -0.8726225  -0.9872248  -0.9961352  -0.99768233 -0.99036324\n",
            "  -0.99933064  0.80823165 -0.51487976  0.3367694   0.9861884  -0.9560756\n",
            "   0.3745508   0.71967596 -0.93753475 -0.25225207  0.9346251 ]\n",
            " [ 0.94373953 -0.8082358   0.47221982 -1.          0.99892926  0.99659216\n",
            "   0.9999171  -0.9349835   0.5151365   0.9999999  -0.9999923   0.99994504\n",
            "   0.962109    0.99999815  0.9967944   0.9998692   0.9999861   0.9977687\n",
            "   0.98518944 -0.9962096   0.17179567  0.03436996  0.9179095   0.60873073\n",
            "   0.9932273  -0.45595247  0.9387296  -0.9621351  -0.99773824]\n",
            " [ 0.81232107 -0.31857345 -0.7393148   0.8213401  -0.77367705 -0.582153\n",
            "  -0.94934326  0.83172697  0.8097747  -0.7861754   0.60023206 -0.8041208\n",
            "   0.24585547 -0.34657112 -0.11666965 -0.3742101  -0.01591683 -0.34916338\n",
            "  -0.8199646  -0.08923824  0.9457054   0.90835696 -0.08257198 -0.64949894\n",
            "  -0.6309928   0.5547663   0.11101697  0.35335413  0.8980397 ]\n",
            " [-0.9972122   0.8818367  -0.9137218   0.9833987   0.23887049 -0.97109705\n",
            "  -0.9995586   0.5963907  -0.49736577 -0.99641037  0.9984792  -0.9756549\n",
            "  -0.9341948  -0.9964018  -0.9768029  -0.99627936 -0.99711275 -0.90075874\n",
            "  -0.98685336  0.77847826  0.29651797 -0.95336914  0.96603376 -0.7656188\n",
            "  -0.03028066 -0.5096506  -0.9845944   0.997363   -0.91438025]]\n",
            "150 [D loss: 0.6892, acc: 0.00%] [G loss: 0.6806, acc: 60.14%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.5  0.49]\n",
            "Disc pred on fake: [0.51 0.48 0.51 0.52 0.47]\n",
            "200 [D loss: 0.6887, acc: 0.00%] [G loss: 0.6761, acc: 64.73%]\n",
            "Disc pred on real: [0.68 0.5  0.5  0.88 0.51]\n",
            "Disc pred on fake: [0.53 0.48 0.5  0.53 0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.8617584  -0.9992237  -0.69756174  0.71001357 -0.9579762  -0.9269592\n",
            "  -0.9487208  -0.23037632 -0.8325993  -0.6277555   0.6862176  -0.73237646\n",
            "  -0.57427144 -0.77559674  0.99813986 -0.9187472  -0.901874    0.86715835\n",
            "   0.99920475 -0.999472    0.14226566  0.14738448  0.9242873  -0.79607815\n",
            "   0.9922854  -0.98910016  0.9945475  -0.9853061  -0.9881909 ]\n",
            " [-0.9670197   0.13547072 -0.99758846  0.99826026 -0.9925968  -0.95614004\n",
            "  -0.99922895 -0.7982703  -0.74829835 -0.9988509   0.99932516 -0.99916804\n",
            "  -0.9639995  -0.99815583  0.9372694  -0.9749548  -0.99696684 -0.685535\n",
            "   0.876827   -0.8703096   0.99657977  0.8985366  -0.67902017 -0.9505025\n",
            "   0.58410406 -0.98972327 -0.98557025  0.05317036  0.6066459 ]\n",
            " [ 1.          0.99212027  1.         -1.          0.9999997   0.99995095\n",
            "   1.          0.5791008   0.9999991   1.         -1.          1.\n",
            "   0.9999491   1.          0.26604304  1.          1.          0.99989\n",
            "  -0.9999061   0.9900253  -0.9999452  -0.9996351  -0.748238    0.9990984\n",
            "  -0.9757924   0.8552709  -0.9751319   0.93624455  0.99980307]\n",
            " [-0.98062307  0.22288145 -0.99694866  0.99637735 -0.9857182  -0.8440841\n",
            "  -0.99754715 -0.9973709  -0.3389582  -0.9945554   0.999146   -0.9991148\n",
            "  -0.6844289  -0.9992121   0.63791895 -0.99758476 -0.99794763 -0.5467297\n",
            "  -0.8629734  -0.8314048   0.97452164  0.17987719  0.5054769  -0.9835009\n",
            "   0.92920214 -0.75330955  0.8003516  -0.6718279  -0.19332644]\n",
            " [-0.9652568  -0.74336183 -0.9896224   0.9908857  -0.9091778   0.3970127\n",
            "  -0.9936071   0.2877478  -0.6854929  -0.98887163  0.98385674 -0.97755694\n",
            "  -0.9218317  -0.9932933  -0.47351953 -0.9507561  -0.9821045  -0.89253306\n",
            "   0.78421456  0.6031715   0.68714607  0.69778746  0.10229414 -0.9843548\n",
            "   0.22462822 -0.7658296   0.2958677   0.65909183 -0.8513583 ]]\n",
            "250 [D loss: 0.6877, acc: 0.00%] [G loss: 0.6730, acc: 66.50%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.5  0.5  0.5  0.49 0.5 ]\n",
            "300 [D loss: 0.6869, acc: 0.00%] [G loss: 0.6712, acc: 66.49%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.84 0.5 ]\n",
            "Disc pred on fake: [0.49 0.49 0.5  0.53 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.9998596   0.81823075 -0.91308284  0.96051604 -0.9152173   0.11809317\n",
            "  -0.9698427   0.6355564  -0.9186075  -0.93035203  0.88552004 -0.796885\n",
            "  -0.20136474 -0.9503469  -0.9570384  -0.99854666 -0.98002416 -0.99071556\n",
            "   0.6298382   0.9626406   0.7822305   0.81385666 -0.03002103 -0.8496872\n",
            "  -0.00799761  0.21611537 -0.94794124  0.6438345   0.52414024]\n",
            " [-0.90799135  0.71846217 -0.9950674   0.9989586  -0.95606935  0.6956562\n",
            "  -0.99627995  0.6704842  -0.9982279  -0.99884295  0.99953574 -0.99962604\n",
            "   0.7315969  -0.9995772   0.971804    0.6836851  -0.9992338   0.9354747\n",
            "   0.37169847 -0.9302204   0.99851966 -0.8603529   0.14040184 -0.3763818\n",
            "   0.8403515   0.72715116 -0.8441577  -0.11261055  0.7794691 ]\n",
            " [-0.9997339   0.7231286  -0.9485537   0.988757   -0.96160156  0.79584545\n",
            "  -0.98924094  0.85120606 -0.96161073 -0.96184325  0.95356035 -0.93180895\n",
            "  -0.01481211 -0.9811928  -0.8267559  -0.99637324 -0.9903773  -0.9429804\n",
            "   0.8116783   0.86144114  0.91956234  0.41263866 -0.16518751 -0.86398435\n",
            "   0.37636757  0.21520889 -0.9409223   0.6349713   0.47505638]\n",
            " [-0.9905226   0.9607384  -0.99843556  0.99906605 -0.9843479   0.898696\n",
            "  -0.9965864   0.97927713 -0.9931249  -0.99958223  0.9971229  -0.998169\n",
            "  -0.07290477 -0.9986946   0.91868585 -0.98881084 -0.9995437  -0.56866384\n",
            "   0.60995305 -0.36577058  0.9944005  -0.40402943 -0.72214895 -0.676988\n",
            "   0.68716335  0.8470185  -0.570958   -0.5831024  -0.46856818]\n",
            " [ 0.3964417   0.77137953 -0.99328035  0.99686444 -0.8252295   0.98486906\n",
            "  -0.99681056  0.60608023 -0.95924944 -0.9985491   0.98293364 -0.999078\n",
            "   0.5600514  -0.9988854   0.9913044   0.7207623  -0.9906788   0.9882731\n",
            "   0.309381   -0.8094158   0.99572325 -0.7607853  -0.91667557 -0.6790641\n",
            "   0.98055077 -0.12157801 -0.82074326  0.91179395  0.4206632 ]]\n",
            "[LightGBM] [Info] Number of positive: 25378, number of negative: 220152\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085316 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 245530, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "Experiment 1 (LGBM) Loop:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [09:37<02:26, 146.49s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_8                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_48 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_32 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_49 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_8                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_50 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_33 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_24          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_51 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_34 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_25          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_52 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_35 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_26          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_53 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_24          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_25          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_26          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_161\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_161\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_70      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_71      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_70[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_71[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_71[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_70      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_71      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6946, acc: 0.00%] [G loss: 0.6823, acc: 79.94%]\n",
            "Disc pred on real: [0.5  0.54 0.58 0.5  0.5 ]\n",
            "Disc pred on fake: [0.5  0.51 0.51 0.51 0.5 ]\n",
            "100 [D loss: 0.6910, acc: 0.00%] [G loss: 0.6808, acc: 74.62%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.51 0.5 ]\n",
            "Disc pred on fake: [0.48 0.47 0.47 0.5  0.51]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[-0.99744695 -0.966957    0.9577632   0.82060313 -0.9483495  -0.9012616\n",
            "  -0.9999391   0.14300247 -0.9719058  -0.99992394 -0.30461735 -0.99995786\n",
            "  -0.7508578  -0.9181276  -0.23301068 -0.83956176  0.774581    0.1588435\n",
            "   0.21827234 -0.94512343  0.59693545 -0.1979847  -0.6620864   0.87772524\n",
            "  -0.9991482   0.5591842   0.50806487  0.322324    0.98016006]\n",
            " [-0.9002509   0.9407109  -0.9908325  -0.99917597 -0.91859776  0.25354078\n",
            "   0.67494965  0.9942778  -0.9555108  -0.95968026  0.9993624  -0.969189\n",
            "   0.05078568 -0.96170783  0.9996859  -0.9538881  -0.9973487  -0.99858403\n",
            "  -0.1532426  -0.7148292   0.6971427   0.51361215 -0.9075827  -0.950992\n",
            "   0.6331217  -0.54369676  0.8878406  -0.37634185 -0.92915165]\n",
            " [ 0.9922318   0.410271    0.9793022   0.9982089   0.98859406  0.78276664\n",
            "   0.9999507  -0.9409936   0.99877745  0.9812212  -0.999686    0.9995748\n",
            "   0.95311236  0.99985427 -0.9997567   0.9999849   0.988118    0.9998633\n",
            "   0.04958742  0.8029219  -0.9806306  -0.88609034 -0.34498397  0.9880107\n",
            "   0.69407064  0.9302389  -0.8641427   0.73123866 -0.66387475]\n",
            " [-0.90790534  0.95670253 -0.99054277 -0.99883574 -0.92861795  0.14729393\n",
            "   0.52590203  0.9942204  -0.96411    -0.9702339   0.9992554  -0.9757185\n",
            "  -0.04467123 -0.9709047   0.9996344  -0.95491743 -0.9974539  -0.998102\n",
            "  -0.25530726 -0.7555425   0.6593115   0.43421987 -0.9252413  -0.95511687\n",
            "   0.6192444  -0.47394222  0.87408483 -0.46212858 -0.93407255]\n",
            " [-0.88336927  0.95853394 -0.9805914  -0.9980739  -0.8510408   0.46690077\n",
            "   0.5667599   0.9920817  -0.9611026  -0.96977556  0.9990345  -0.9539863\n",
            "  -0.26281655 -0.9663586   0.99887294 -0.9377029  -0.99684536 -0.9976657\n",
            "  -0.27800667 -0.5976196   0.5314839   0.30777687 -0.8836489  -0.94226664\n",
            "   0.7659052  -0.5308373   0.91852885 -0.48784676 -0.8536243 ]]\n",
            "150 [D loss: 0.6901, acc: 0.00%] [G loss: 0.6762, acc: 73.90%]\n",
            "Disc pred on real: [0.5  0.5  0.49 0.5  0.5 ]\n",
            "Disc pred on fake: [0.51 0.5  0.48 0.51 0.51]\n",
            "200 [D loss: 0.6889, acc: 0.00%] [G loss: 0.6736, acc: 74.12%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.5  0.49]\n",
            "Disc pred on fake: [0.51 0.51 0.5  0.5  0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[ 0.9999734  -0.60549515  1.         -0.99938494 -0.99999917  0.9999757\n",
            "  -1.         -1.          1.          1.         -1.          1.\n",
            "  -0.9999938   1.          0.98144054  1.          1.         -0.9849749\n",
            "  -0.9919091  -0.99948674  0.99997735 -0.91125846 -0.9543109   0.9998625\n",
            "  -1.         -0.1857973   0.79550725 -0.99947697  0.41540784]\n",
            " [-0.9112747  -0.6470545  -0.9454462   0.9573556   0.8958988  -0.8998382\n",
            "   0.27487567  0.6859651  -0.8026698  -0.97735614  0.99449867 -0.9951435\n",
            "   0.5720067  -0.9932612   0.15975095 -0.9760851  -0.99170357 -0.95547855\n",
            "   0.52892673  0.43949726 -0.574897    0.48881602  0.92383134 -0.9016312\n",
            "   0.91576606  0.95411336 -0.20739365  0.47526997 -0.32842907]\n",
            " [-0.95063853 -0.86511064  0.9177756  -0.905573   -0.9753575   0.99021876\n",
            "  -0.52502304 -0.9653789   0.999858    0.99967605 -0.9999851   0.9545307\n",
            "  -0.8630913   0.99998593 -0.76251334  0.99849457  0.9999913   0.9409902\n",
            "   0.0923165  -0.3933285   0.9306026  -0.32089514 -0.9939924  -0.09837402\n",
            "  -0.90986514 -0.98428833  0.5810394  -0.99968064 -0.30485177]\n",
            " [-0.9115432  -0.61800504 -0.9466123   0.9572847   0.8890834  -0.9022981\n",
            "   0.24325763  0.6861179  -0.7990557  -0.9781458   0.9941234  -0.99517995\n",
            "   0.5796921  -0.9932968   0.16915926 -0.97721255 -0.9915848  -0.9584418\n",
            "   0.5446511   0.42709458 -0.56326014  0.49152097  0.92515844 -0.9004767\n",
            "   0.91835946  0.95571923 -0.19008473  0.47972456 -0.33935112]\n",
            " [-0.90732515 -0.5938786  -0.9445926   0.95251393  0.89120173 -0.89736366\n",
            "   0.2618953   0.6778295  -0.7929055  -0.9790078   0.9945307  -0.99513835\n",
            "   0.586417   -0.9935716   0.21325767 -0.9767065  -0.9913926  -0.96088934\n",
            "   0.52346766  0.4341657  -0.5530359   0.48448238  0.92830694 -0.89612526\n",
            "   0.91610384  0.95435935 -0.19635798  0.46374354 -0.35303628]]\n",
            "250 [D loss: 0.6885, acc: 0.00%] [G loss: 0.6718, acc: 73.65%]\n",
            "Disc pred on real: [0.5  0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.5  0.5  0.49 0.49 0.5 ]\n",
            "300 [D loss: 0.6873, acc: 0.00%] [G loss: 0.6717, acc: 72.01%]\n",
            "Disc pred on real: [0.49 0.5  0.49 0.49 0.49]\n",
            "Disc pred on fake: [0.49 0.5  0.5  0.5  0.48]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.4121613   0.989411   -0.99641836  0.99960387 -0.98816484 -0.43837574\n",
            "   0.10621504 -0.8667742   0.9972699  -0.94536287  0.9962179  -0.99986356\n",
            "   0.898641    0.14785072  0.9776987  -0.99908876 -0.99675184 -0.7127708\n",
            "  -0.63269186 -0.37831968  0.9387931   0.3128436  -0.31316993 -0.59063685\n",
            "  -0.31111172  0.02956242 -0.7198732  -0.40008667  0.29866928]\n",
            " [ 0.50813484 -0.20332418 -0.9920747   0.9873294   0.17712568  0.88916945\n",
            "  -0.95356077 -0.9573903   0.9534747  -0.99501055  0.9996246  -0.9993788\n",
            "   0.7738982  -0.9991688   0.5115288  -0.98347586 -0.99958926  0.9668346\n",
            "  -0.89988995  0.47318685  0.15698323  0.0583797   0.9502468  -0.9275287\n",
            "  -0.4608252   0.8343216  -0.78755933  0.9208283  -0.2662991 ]\n",
            " [-0.9119891   0.9301026  -0.99642557  0.99953896 -0.99914575 -0.6310123\n",
            "  -0.83564657 -0.76061     0.99577844 -0.9018493   0.9453664  -0.99988204\n",
            "   0.9452808   0.3826441   0.9973747  -0.99823767 -0.97974163  0.06594519\n",
            "  -0.9270469  -0.4881924   0.87980664  0.46570596  0.407636   -0.20001213\n",
            "  -0.05138098  0.69750285 -0.93268377  0.5092654   0.08550821]\n",
            " [ 0.5201081  -0.16806181 -0.9919266   0.98659366  0.20691638  0.89467204\n",
            "  -0.9499077  -0.9576564   0.9558959  -0.99520063  0.9996157  -0.99935967\n",
            "   0.77965987 -0.99923754  0.50038004 -0.98281884 -0.99958616  0.9668526\n",
            "  -0.9005813   0.4961772   0.1464928   0.05620403  0.9521303  -0.9236248\n",
            "  -0.45784798  0.83568573 -0.7909697   0.92053586 -0.2738355 ]\n",
            " [ 0.5423749  -0.14389242 -0.99171764  0.98781216  0.15223368  0.90102214\n",
            "  -0.94980913 -0.95882165  0.94979936 -0.99516475  0.99961495 -0.99936706\n",
            "   0.7853677  -0.99923545  0.5186466  -0.983088   -0.99959075  0.96491295\n",
            "  -0.89397717  0.48916742  0.14691466  0.06117414  0.95103437 -0.9237189\n",
            "  -0.47507045  0.8245326  -0.7907132   0.92165315 -0.2722791 ]]\n",
            "[LightGBM] [Info] Number of positive: 25378, number of negative: 220152\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082820 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 245530, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
            "[LightGBM] [Info] Start training from score -0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning:\n",
            "\n",
            "X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "\n",
            "Experiment 1 (LGBM) Loop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [12:03<00:00, 144.68s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d7b540a"
      },
      "source": [
        "**Reasoning**:\n",
        "Summarize the findings from the plot based on the previous analysis.\n",
        "\n"
      ],
      "id": "8d7b540a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dfb1f9a"
      },
      "source": [
        "\n",
        "*   As the percentage of fraud training data used to train the GAN increases from 0.01% to 1.0%, there is a general upward trend observed in all three classifier performance metrics: ROC-AUC, PR-AUC, and F1-score.\n",
        "*   Training the GAN with a larger proportion of the available fraud data appears to result in the generation of more effective synthetic data, which subsequently enhances the classifier's ability to differentiate between fraudulent and non-fraudulent transactions on the test set.\n"
      ],
      "id": "5dfb1f9a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strength: Extremely strong and stable ROC-AUC (~0.975â€“0.98), showing reliable ranking ability.\n",
        "\n",
        "Weakness: PR-AUC and F1 are more variable at smaller training sizes, reflecting challenges in minority fraud recall.\n",
        "\n",
        "Best Performance: Achieved at larger fraud training sizes (â‰¥80â€“100%), where both PR-AUC (~0.825) and F1 (~0.82) recover.\n",
        "\n",
        "Overall: CGAN + LGBM is a highly effective approach for fraud detection with excellent ROC stability, though precision-recall tradeoff requires more fraud samples to stabilize."
      ],
      "metadata": {
        "id": "Jv-oSJ-JQ9Wh"
      },
      "id": "Jv-oSJ-JQ9Wh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referneces-[A hybrid deep learning approach with generative adversarial network for credit card fraud detection](https://doi.org/10.3390/technologies12100186), [Improving detection of credit card fraudulent transactions using generative adversarial networks](https://arxiv.org/abs/1907.03355), [Generative adversarial network for oversampling data in credit card fraud detection](https://link.springer.com/chapter/10.1007/978-3-030-36945-3_7)"
      ],
      "metadata": {
        "id": "XDBwinA9RGRE"
      },
      "id": "XDBwinA9RGRE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Note- ChatGPT used for understanding results ."
      ],
      "metadata": {
        "id": "2LRKAbY7RKNw"
      },
      "id": "2LRKAbY7RKNw"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bwD8-QJBQyDJ"
      },
      "id": "bwD8-QJBQyDJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 310,
          "sourceId": 23498,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30822,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1846.66889,
      "end_time": "2024-12-30T03:00:04.367340",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-30T02:29:17.698450",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}