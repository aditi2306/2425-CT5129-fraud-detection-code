{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CGAN with RF as classifier with different datasizes"
      ],
      "metadata": {
        "id": "has9fE1XIOly"
      },
      "id": "has9fE1XIOly"
    },
    {
      "cell_type": "markdown",
      "id": "95b87982",
      "metadata": {
        "id": "95b87982"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cb2d1424",
      "metadata": {
        "id": "cb2d1424"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,\\\n",
        "                            accuracy_score, balanced_accuracy_score,classification_report,\\\n",
        "                            confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "QgenRhZYJcmv",
      "metadata": {
        "id": "QgenRhZYJcmv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a60195",
      "metadata": {
        "id": "90a60195"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "79bf21d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bf21d7",
        "outputId": "0dec252a-4044-4875-c664-260fb83591c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      284807 non-null  float64\n",
            " 1   V2      284807 non-null  float64\n",
            " 2   V3      284807 non-null  float64\n",
            " 3   V4      284807 non-null  float64\n",
            " 4   V5      284807 non-null  float64\n",
            " 5   V6      284807 non-null  float64\n",
            " 6   V7      284807 non-null  float64\n",
            " 7   V8      284807 non-null  float64\n",
            " 8   V9      284807 non-null  float64\n",
            " 9   V10     284807 non-null  float64\n",
            " 10  V11     284807 non-null  float64\n",
            " 11  V12     284807 non-null  float64\n",
            " 12  V13     284807 non-null  float64\n",
            " 13  V14     284807 non-null  float64\n",
            " 14  V15     284807 non-null  float64\n",
            " 15  V16     284807 non-null  float64\n",
            " 16  V17     284807 non-null  float64\n",
            " 17  V18     284807 non-null  float64\n",
            " 18  V19     284807 non-null  float64\n",
            " 19  V20     284807 non-null  float64\n",
            " 20  V21     284807 non-null  float64\n",
            " 21  V22     284807 non-null  float64\n",
            " 22  V23     284807 non-null  float64\n",
            " 23  V24     284807 non-null  float64\n",
            " 24  V25     284807 non-null  float64\n",
            " 25  V26     284807 non-null  float64\n",
            " 26  V27     284807 non-null  float64\n",
            " 27  V28     284807 non-null  float64\n",
            " 28  Amount  284807 non-null  float64\n",
            " 29  Class   284807 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('./creditcard.csv')\n",
        "df=df.drop('Time',axis=1)\n",
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a828e2f8",
      "metadata": {
        "id": "a828e2f8"
      },
      "source": [
        "PCA Transformation: The description of the data says that all the features went through a PCA transformation (Except for time and amount).  \n",
        "Scaling: Keep in mind that in order to implement a PCA transformation features need to be previously scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b13394f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "b13394f3",
        "outputId": "00c7b949-5485-4488-997d-f7bb14f5b1cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 V1            V2            V3            V4            V5  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15  9.604066e-16   \n",
              "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
              "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
              "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
              "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
              "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
              "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
              "\n",
              "                 V6            V7            V8            V9           V10  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15  2.239053e-15   \n",
              "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
              "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
              "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
              "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
              "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
              "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72d23778-d6a8-44bc-af10-75681671d92e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>2.239053e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72d23778-d6a8-44bc-af10-75681671d92e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72d23778-d6a8-44bc-af10-75681671d92e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72d23778-d6a8-44bc-af10-75681671d92e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-991bf880-1989-4428-be5f-434f3010e3e0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-991bf880-1989-4428-be5f-434f3010e3e0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-991bf880-1989-4428-be5f-434f3010e3e0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "306b3e6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306b3e6f",
        "outputId": "b9183f05-f8ed-44a2-afbb-ff13388a7446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 9144 duplicate rows\n"
          ]
        }
      ],
      "source": [
        "# checking for duplicate values\n",
        "print(f\"Dataset has {df.duplicated().sum()} duplicate rows\")\n",
        "# dropping duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8b2f4c06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b2f4c06",
        "outputId": "81142d52-5279-4abe-9ba2-29e0b31531e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 275663 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      275663 non-null  float64\n",
            " 1   V2      275663 non-null  float64\n",
            " 2   V3      275663 non-null  float64\n",
            " 3   V4      275663 non-null  float64\n",
            " 4   V5      275663 non-null  float64\n",
            " 5   V6      275663 non-null  float64\n",
            " 6   V7      275663 non-null  float64\n",
            " 7   V8      275663 non-null  float64\n",
            " 8   V9      275663 non-null  float64\n",
            " 9   V10     275663 non-null  float64\n",
            " 10  V11     275663 non-null  float64\n",
            " 11  V12     275663 non-null  float64\n",
            " 12  V13     275663 non-null  float64\n",
            " 13  V14     275663 non-null  float64\n",
            " 14  V15     275663 non-null  float64\n",
            " 15  V16     275663 non-null  float64\n",
            " 16  V17     275663 non-null  float64\n",
            " 17  V18     275663 non-null  float64\n",
            " 18  V19     275663 non-null  float64\n",
            " 19  V20     275663 non-null  float64\n",
            " 20  V21     275663 non-null  float64\n",
            " 21  V22     275663 non-null  float64\n",
            " 22  V23     275663 non-null  float64\n",
            " 23  V24     275663 non-null  float64\n",
            " 24  V25     275663 non-null  float64\n",
            " 25  V26     275663 non-null  float64\n",
            " 26  V27     275663 non-null  float64\n",
            " 27  V28     275663 non-null  float64\n",
            " 28  Amount  275663 non-null  float64\n",
            " 29  Class   275663 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5128908",
      "metadata": {
        "id": "c5128908"
      },
      "source": [
        "There is no null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9d6c996a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6c996a",
        "outputId": "f5c7dced-b0f4-45cf-bdb5-b60fb3bf5b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Frauds 99.83 % of the dataset\n",
            "Frauds 0.17 % of the dataset\n"
          ]
        }
      ],
      "source": [
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d88ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "d88ad047",
        "outputId": "5d32c318-0449-4ace-b481-3a5583c7cde3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Class', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(data=df,x='Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "30728ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "30728ee8",
        "outputId": "a8c2390c-1a42-443f-a68e-b3709f58012a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V1        -3.273070\n",
              "V2        -4.653486\n",
              "V3        -2.216730\n",
              "V4         0.681387\n",
              "V5        -2.458790\n",
              "V6         1.867576\n",
              "V7         2.877722\n",
              "V8        -8.292631\n",
              "V9         0.550965\n",
              "V10        1.242165\n",
              "V11        0.347772\n",
              "V12       -2.208171\n",
              "V13        0.061058\n",
              "V14       -1.953613\n",
              "V15       -0.295836\n",
              "V16       -1.048371\n",
              "V17       -3.802987\n",
              "V18       -0.255710\n",
              "V19        0.115957\n",
              "V20       -2.045060\n",
              "V21        2.784302\n",
              "V22       -0.200868\n",
              "V23       -5.805236\n",
              "V24       -0.545636\n",
              "V25       -0.408260\n",
              "V26        0.587603\n",
              "V27       -0.745732\n",
              "V28       11.400938\n",
              "Amount    16.841622\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>-3.273070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>-4.653486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>-2.216730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0.681387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>-2.458790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>1.867576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>2.877722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>-8.292631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0.550965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>1.242165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0.347772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>-2.208171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0.061058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>-1.953613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>-0.295836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>-1.048371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>-3.802987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>-0.255710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0.115957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>-2.045060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>2.784302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>-0.200868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>-5.805236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>-0.545636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>-0.408260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0.587603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>-0.745732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>11.400938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <td>16.841622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.drop('Class',axis=1).skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85bb3774",
      "metadata": {
        "id": "85bb3774"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7ab1142e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ab1142e",
        "outputId": "294706b8-74f6-47a4-f314-09b89be9054c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(275663, 29) (275663,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df.drop('Class', axis=1))\n",
        "y = df['Class'].values\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e31517",
      "metadata": {
        "id": "22e31517"
      },
      "source": [
        "## Splitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa74b00",
      "metadata": {
        "id": "6fa74b00"
      },
      "source": [
        "we want to test our models on the original testing set not on the testing set created from GAN. The main goal is to fit the model in the generated data, and test it on the original testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f8303d35",
      "metadata": {
        "id": "f8303d35"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50b98b70",
      "metadata": {
        "id": "50b98b70"
      },
      "source": [
        "## Conditional GAN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, multiply, LeakyReLU, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class cGAN():\n",
        "    def __init__(self):\n",
        "        self.latent_dim = 32\n",
        "        self.out_shape = 29\n",
        "        self.num_classes = 2\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,))\n",
        "        gen_samples = self.generator([noise, label])\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator([gen_samples, label])\n",
        "\n",
        "        self.combined = Model([noise, label], valid)\n",
        "        self.combined.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(0.0002, 0.5),\n",
        "                              metrics=['accuracy'])\n",
        "        self.combined.summary()\n",
        "\n",
        "    def build_generator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(self.out_shape, activation='tanh'))\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
        "        model_input = multiply([noise, label_embedding])\n",
        "        gen_sample = model(model_input)\n",
        "\n",
        "        return Model([noise, label], gen_sample, name=\"Generator\")\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(GaussianNoise(0.1, input_shape=(self.out_shape,)))\n",
        "        model.add(Dense(256, kernel_initializer=init, kernel_regularizer=l2(0.001)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        gen_sample = Input(shape=(self.out_shape,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.out_shape)(label))\n",
        "        model_input = multiply([gen_sample, label_embedding])\n",
        "        validity = model(model_input)\n",
        "\n",
        "        return Model([gen_sample, label], validity, name=\"Discriminator\")\n",
        "\n",
        "    def train(self, X_train, y_train, pos_index, neg_index, epochs, batch_size=32, sample_interval=50):\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # === Train Discriminator ===\n",
        "            idx1 = np.random.choice(pos_index, 8)\n",
        "            idx0 = np.random.choice(neg_index, batch_size - 8)\n",
        "            idx = np.concatenate((idx1, idx0))\n",
        "            samples, labels = X_train[idx], y_train[idx]\n",
        "            samples, labels = shuffle(samples, labels)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_samples = self.generator.predict([noise, labels], verbose=0)\n",
        "\n",
        "            valid_smooth = np.random.uniform(low=0.9, high=1.0, size=(batch_size, 1))\n",
        "            fake_smooth = np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
        "\n",
        "            if np.random.rand() < 0.05:\n",
        "                valid_smooth, fake_smooth = fake_smooth, valid_smooth\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "            d_loss_real = self.discriminator.train_on_batch([samples, labels], valid_smooth)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([gen_samples, labels], fake_smooth)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # === Train Generator ===\n",
        "            self.discriminator.trainable = False\n",
        "            sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
        "\n",
        "\n",
        "            if (epoch + 1) % sample_interval == 0:\n",
        "                print(f\"{epoch + 1} [D loss: {d_loss[0]:.4f}, acc: {100*d_loss[1]:.2f}%] \"\n",
        "                      f\"[G loss: {g_loss[0]:.4f}, acc: {100*g_loss[1]:.2f}%]\")\n",
        "\n",
        "                d_real_pred = self.discriminator.predict([samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                d_fake_pred = self.discriminator.predict([gen_samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                print(\"Disc pred on real:\", np.round(d_real_pred, 2))\n",
        "                print(\"Disc pred on fake:\", np.round(d_fake_pred, 2))\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                self.save_generated_samples(epoch + 1)\n",
        "\n",
        "    def save_generated_samples(self, epoch):\n",
        "        noise = np.random.normal(0, 1, (5, self.latent_dim))\n",
        "        labels = np.array([[0], [1], [0], [1], [1]])\n",
        "        gen_samples = self.generator.predict([noise, labels])\n",
        "        print(f\"Generated samples at epoch {epoch}:\\n{gen_samples}\")"
      ],
      "metadata": {
        "id": "zL2u47WRNTOr"
      },
      "id": "zL2u47WRNTOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d2d7879",
      "metadata": {
        "id": "2d2d7879"
      },
      "source": [
        "## Training GAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def experiment_1_scaling_gan(GAN_class, X_train, y_train, X_test, y_test, scaler, epochs=300, latent_dim=32):\n",
        "\n",
        "\n",
        "    fraud_data = X_train[y_train == 1]\n",
        "    nonfraud_data = X_train[y_train == 0]\n",
        "\n",
        "    # Percentages to test\n",
        "    sizes = [0.01, 0.05, 0.1, 0.5, 1.0]\n",
        "    results = []\n",
        "\n",
        "    for frac in tqdm(sizes, desc=\"Experiment 1 Loop\"):\n",
        "        sample_size = int(len(fraud_data) * frac)\n",
        "        fraud_subset = fraud_data[:sample_size]\n",
        "\n",
        "\n",
        "        combined_X = np.vstack([fraud_subset, nonfraud_data])\n",
        "        combined_y = np.vstack([\n",
        "            np.ones((sample_size, 1)),\n",
        "            np.zeros((len(nonfraud_data), 1))\n",
        "        ])\n",
        "\n",
        "\n",
        "        idx_pos = np.where(combined_y == 1)[0]\n",
        "        idx_neg = np.where(combined_y == 0)[0]\n",
        "\n",
        "        # Train GAN on current subset\n",
        "        gan = GAN_class()\n",
        "        gan.train(combined_X, combined_y, idx_pos, idx_neg, epochs=epochs, batch_size=64)\n",
        "\n",
        "\n",
        "        noise = np.random.normal(0, 1, (25000, latent_dim))\n",
        "\n",
        "        gen_labels = np.ones((25000, 1))\n",
        "        gen_samples = gan.generator.predict([noise, gen_labels], verbose=0)\n",
        "\n",
        "        # Combine real+synthetic fraud for classifier training\n",
        "        aug_X = np.vstack([X_train, gen_samples])\n",
        "        aug_y = np.vstack([y_train.reshape(-1, 1), np.ones((25000, 1))]).ravel()\n",
        "\n",
        "\n",
        "        # Train classifier on augmented data\n",
        "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        clf.fit(aug_X, aug_y)\n",
        "\n",
        "\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Metrics\n",
        "        roc = roc_auc_score(y_test, y_prob)\n",
        "        pr = average_precision_score(y_test, y_prob)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        results.append((int(frac*100), roc, pr, f1))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "sEpb9XQMcPV2"
      },
      "id": "sEpb9XQMcPV2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_experiment_1(results):\n",
        "    import matplotlib.pyplot as plt\n",
        "    x = [r[0] for r in results]\n",
        "    roc = [r[1] for r in results]\n",
        "    pr = [r[2] for r in results]\n",
        "    f1 = [r[3] for r in results]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, roc, label=\"ROC-AUC\", marker='o')\n",
        "    plt.plot(x, pr, label=\"PR-AUC\", marker='s')\n",
        "    plt.plot(x, f1, label=\"F1-score\", marker='^')\n",
        "    plt.xlabel(\"Fraud Training Set Size (%)\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.title(\"Experiment 1: Model Performance vs GAN Training Size\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "H9xs58f5cABu"
      },
      "id": "H9xs58f5cABu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "01d0b0fa",
        "outputId": "392ca018-ef04-4e7d-f891-65e084570ad9"
      },
      "source": [
        "# Instantiate the cGAN class\n",
        "cgan_model = cGAN()\n",
        "\n",
        "# Fix the function call to pass the cGAN class\n",
        "results = experiment_1_scaling_gan(cGAN, X_train, y_train, X_test, y_test, scaler)\n",
        "plot_experiment_1(results)"
      ],
      "id": "01d0b0fa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_1                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_1                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_6 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_7 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_35\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_14      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_15      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_14[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_15[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_15[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_14      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_15      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 Loop:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_2                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_2                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_10 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_11 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_53\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_53\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_22      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_23      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_22[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_23[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_23[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_22      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_23      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6944, acc: 0.00%] [G loss: 0.6880, acc: 70.44%]\n",
            "Disc pred on real: [0.5  0.5  0.58 0.5  0.5 ]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6892, acc: 0.00%] [G loss: 0.6857, acc: 65.73%]\n",
            "Disc pred on real: [0.5  0.54 0.49 0.51 0.5 ]\n",
            "Disc pred on fake: [0.51 0.48 0.48 0.48 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.9377385  -0.23458594  0.94420636 -0.75891644  0.84133786  0.77012503\n",
            "   0.83940244 -0.42854688 -0.3680846   0.19081612 -0.9550124  -0.18575671\n",
            "   0.0938883   0.595673   -0.62798417  0.75458086  0.8592005  -0.9463574\n",
            "  -0.5936686   0.49045253  0.94443774 -0.94278604  0.27565566  0.37319335\n",
            "  -0.48514712  0.9281458   0.92334473 -0.7773335   0.6948904 ]\n",
            " [ 0.62321407 -0.71185374  0.8329286   0.70499355  0.22810306 -0.74634284\n",
            "  -0.9657838  -0.32459092 -0.400537    0.16191709 -0.9153986   0.48822987\n",
            "   0.7700164   0.01766161  0.8904899   0.89025533  0.05197826  0.92443556\n",
            "   0.12761386 -0.23341729 -0.50637966 -0.53944415 -0.83450913 -0.8845565\n",
            "  -0.77805847  0.887538   -0.67555004 -0.9852639   0.7943271 ]\n",
            " [ 0.19720787 -0.03481615  0.9783786  -0.75734335  0.64280915  0.5123949\n",
            "  -0.4416568  -0.340372   -0.17991802 -0.1375707   0.52973634  0.56129414\n",
            "  -0.5509914  -0.14708738  0.53662705 -0.5099952   0.81897175 -0.29999453\n",
            "   0.37238252  0.12900832  0.88986886  0.05454293 -0.14013675  0.7768167\n",
            "   0.6433902  -0.01463679  0.6048847   0.70495605  0.21418783]\n",
            " [ 0.21931462 -0.4699784  -0.14983593  0.18386906  0.36109453 -0.4655151\n",
            "  -0.0253489  -0.92796665 -0.9141603  -0.06558401 -0.64369005  0.86428875\n",
            "   0.05587473  0.5780161   0.27257785  0.56935436 -0.5797007  -0.2936989\n",
            "   0.70366454  0.73077804  0.310849   -0.7454588   0.88053364  0.62652296\n",
            "   0.9134938   0.5987811   0.66875297 -0.04429549  0.9431478 ]\n",
            " [ 0.28862193  0.85058296 -0.4871548  -0.14791462 -0.54736495  0.5426776\n",
            "   0.92994845  0.9404635  -0.66583467  0.22325322  0.65519124 -0.97886914\n",
            "   0.9415871   0.0623186  -0.02184547 -0.53054816 -0.06696945 -0.2029243\n",
            "  -0.8010253   0.86608726  0.92221344 -0.05163392 -0.06219507  0.20515554\n",
            "   0.9894574  -0.29594597 -0.84788984  0.9284684  -0.419316  ]]\n",
            "150 [D loss: 0.6867, acc: 0.00%] [G loss: 0.6778, acc: 66.95%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.5  0.49]\n",
            "Disc pred on fake: [0.52 0.52 0.49 0.53 0.54]\n",
            "200 [D loss: 0.6875, acc: 0.00%] [G loss: 0.6714, acc: 69.99%]\n",
            "Disc pred on real: [0.49 0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.48 0.52 0.51 0.51 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[ 0.99873626  0.9050752  -0.44928822  0.6278566   0.8758189  -0.24523373\n",
            "  -0.84340864 -0.85643005 -0.9771641  -0.46317658  0.52773327 -0.24810609\n",
            "  -0.04198689 -0.13613158 -0.70072854 -0.70907044 -0.81392694 -0.47706527\n",
            "   0.3799159   0.7348848  -0.4356916   0.91632444 -0.7592867   0.51919377\n",
            "   0.81806743 -0.13986419 -0.68287426  0.03789793 -0.93842804]\n",
            " [ 0.8236947  -0.8468894  -0.9501386  -0.7941083  -0.7521225   0.08656847\n",
            "  -0.86128396 -0.48431212  0.82624286 -0.87844914  0.96466404 -0.9660795\n",
            "  -0.15985128 -0.99228084  0.99790865 -0.95565844 -0.50903165  0.10101404\n",
            "   0.8223443  -0.9924245   0.4998921   0.9156246   0.907005   -0.9330122\n",
            "   0.5320043   0.07722563 -0.8834811  -0.9741221  -0.41635057]\n",
            " [-0.89513737 -0.9998348   1.          0.78484946 -0.98786736  0.8651836\n",
            "   1.          0.99908173  0.9966086   0.99999917 -1.          1.\n",
            "  -0.990139    1.         -0.4950808   1.          0.9999987   1.\n",
            "  -1.          0.9599636   0.7579293  -1.         -0.24893788 -0.9836216\n",
            "  -0.9998562  -0.96042454  0.9999985   0.9422875   0.9999719 ]\n",
            " [ 0.41462535  0.9623025  -0.8362667   0.7912612   0.1629386   0.9557415\n",
            "  -0.7339433  -0.57677186  0.93174154 -0.6124911   0.9472474  -0.95988035\n",
            "  -0.8833181  -0.99057233  0.7701648  -0.8763151  -0.9679355  -0.90472704\n",
            "   0.90246415 -0.24255069 -0.4404214   0.75432205  0.6701435  -0.13518083\n",
            "   0.68999386 -0.534138   -0.9546308   0.15045093 -0.43532243]\n",
            " [-0.02238299  0.43281302 -0.99563175 -0.52741534 -0.64142483  0.5713243\n",
            "  -0.98536164  0.4441058  -0.71469533 -0.97378516  0.9796637  -0.97298133\n",
            "   0.54127336 -0.9613978   0.8630475  -0.9787471  -0.9858994  -0.94822544\n",
            "   0.94845366 -0.89370775 -0.19941239  0.9529008  -0.31198248 -0.6096792\n",
            "   0.72961026 -0.18270144 -0.93006104 -0.87220496 -0.5306565 ]]\n",
            "250 [D loss: 0.6870, acc: 0.00%] [G loss: 0.6693, acc: 71.69%]\n",
            "Disc pred on real: [0.5  0.49 0.5  0.49 0.49]\n",
            "Disc pred on fake: [0.5  0.48 0.48 0.51 0.48]\n",
            "300 [D loss: 0.6866, acc: 0.00%] [G loss: 0.6689, acc: 71.78%]\n",
            "Disc pred on real: [0.49 0.74 0.49 0.5  0.49]\n",
            "Disc pred on fake: [0.5  0.53 0.5  0.5  0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[ 0.9212755   0.77650297  0.9983443  -0.44460848 -0.99149305  0.9975193\n",
            "   0.98402685 -0.80082166 -0.5127484   0.96559143 -0.9928508   0.99367476\n",
            "  -0.9983089   0.9995349  -0.38709068 -0.6333642   0.9262233   0.97950536\n",
            "   0.9999504  -0.9958646  -0.6417438   0.99936646  0.05461538 -0.9520931\n",
            "   0.99953943  0.63783836  0.9722326   0.5457288  -0.9943004 ]\n",
            " [-0.9921911   0.9860927  -0.9934834   0.7191996   0.46061677 -0.85557073\n",
            "  -0.9920321  -0.8740413   0.850136   -0.9926256   0.9954194  -0.99775106\n",
            "   0.9872909  -0.99898916 -0.3895574  -0.99223983 -0.97986    -0.7466832\n",
            "   0.66860336 -0.40547767 -0.38688943 -0.5895615  -0.5232017   0.7356846\n",
            "  -0.16698125 -0.5245638  -0.9729414   0.8943008   0.85889256]\n",
            " [ 0.38331044 -0.6904973  -0.7455321   0.78960186  0.94226646 -0.57698256\n",
            "  -0.7716569   0.92209727 -0.75193757 -0.71587515  0.8392639  -0.89420134\n",
            "   0.99082565 -0.88928473 -0.9888684   0.7481891  -0.8230334  -0.41292307\n",
            "  -0.9985809   0.9704272   0.8895868  -0.99782145 -0.76222515  0.1903005\n",
            "  -0.8621067  -0.25471056 -0.6871853  -0.59254146  0.9563111 ]\n",
            " [-0.9424478  -0.83079547 -0.9880161  -0.573198    0.8139422  -0.9989675\n",
            "  -0.98712766 -0.07891419 -0.05435172 -0.9936957   0.97959036 -0.9832495\n",
            "   0.99334764 -0.9935705   0.7731622  -0.83755904 -0.9917126  -0.9557006\n",
            "  -0.82877797  0.80478406  0.74741924 -0.9875021   0.8409928   0.76756877\n",
            "  -0.6105105   0.9763617  -0.9325497  -0.9048433  -0.14043576]\n",
            " [-0.95807236  0.8971789  -0.9899719   0.8591904  -0.21377586 -0.9116875\n",
            "  -0.98848736 -0.30497688  0.62047756 -0.96652997  0.984604   -0.98742557\n",
            "   0.98721296 -0.99641615 -0.80787545 -0.74355304 -0.990373   -0.89858\n",
            "  -0.44666764  0.34832472  0.23720154 -0.7887529  -0.79458994  0.56012297\n",
            "  -0.853514   -0.6593189  -0.9594215   0.6998471   0.31913382]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 Loop:  20%|â–ˆâ–ˆ        | 1/5 [07:10<28:41, 430.47s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_3                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_19 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_3                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_13 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_14 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_15 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_9           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_10          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_30      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_31      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_30[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_31[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_31[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_30      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_31      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6889, acc: 0.00%] [G loss: 0.6897, acc: 60.94%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.51 0.5 ]\n",
            "Disc pred on fake: [0.5  0.5  0.5  0.5  0.51]\n",
            "100 [D loss: 0.6841, acc: 0.00%] [G loss: 0.6870, acc: 59.08%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.47 0.47 0.5  0.47 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.32337537 -0.99232197  0.67005587  0.5621238   0.9566981   0.47206518\n",
            "   0.99863386 -0.9471644   0.9466023   0.99991703 -0.9993347   0.98763573\n",
            "   0.02519632  0.5897217  -0.5353575   0.99022543  0.96185046 -0.41625187\n",
            "  -0.41946515 -0.21094932 -0.77658117  0.05060793 -0.95247084  0.15309323\n",
            "   0.38581702  0.46869344  0.6353664   0.85843533  0.49800405]\n",
            " [ 0.46229538 -0.26746762  0.0693172   0.36676344 -0.75317997 -0.01130615\n",
            "  -0.99581796 -0.6678028  -0.97634697 -0.9988995   0.99477476 -0.20232898\n",
            "  -0.15825704 -0.9743301  -0.22088516 -0.997682   -0.6442363  -0.02116709\n",
            "   0.99680763  0.47764483  0.52577245  0.9588397   0.8727497  -0.9937739\n",
            "  -0.9945615   0.8744898  -0.55400985 -0.24829437 -0.9460115 ]\n",
            " [ 0.3230437  -0.81924367  0.6034018   0.9820084   0.9460021  -0.5542835\n",
            "   0.98152614 -0.83997476 -0.8603351   0.99520546 -0.992049   -0.39256454\n",
            "  -0.88036335 -0.41500732  0.148864   -0.39163864 -0.9610128   0.7711372\n",
            "  -0.9835057  -0.10249379 -0.48286012  0.11834221  0.7182082   0.8622512\n",
            "  -0.68273985 -0.08139496  0.9278524   0.17106639  0.41216278]\n",
            " [-0.2068656   0.9200776   0.983795   -0.8786737  -0.99017423 -0.95089054\n",
            "  -0.99920124  0.9525532  -0.8819814  -0.99999267  0.99994713 -0.8655473\n",
            "   0.21428691 -0.6888726   0.28156334 -0.9958645   0.35783657  0.19976933\n",
            "   0.9276855   0.93764013  0.37765157 -0.97775066  0.7633703  -0.999388\n",
            "  -0.9942911   0.48464817 -0.44996306  0.6048291  -0.97232234]\n",
            " [-0.8762129   0.9295366   0.42499533  0.20326056 -0.9802749   0.15811467\n",
            "  -0.9532393   0.10264795 -0.686474   -0.872649    0.9623471  -0.9297518\n",
            "   0.77059066 -0.6366663   0.72954166 -0.9714038  -0.98068386 -0.8400156\n",
            "   0.7053178   0.79284936  0.80335015 -0.08134554  0.16545933 -0.5693054\n",
            "  -0.7578035   0.96000564 -0.15982012  0.85863584  0.3689291 ]]\n",
            "150 [D loss: 0.6833, acc: 0.00%] [G loss: 0.6844, acc: 60.62%]\n",
            "Disc pred on real: [0.49 0.48 0.75 0.5  0.5 ]\n",
            "Disc pred on fake: [0.46 0.52 0.53 0.52 0.46]\n",
            "200 [D loss: 0.6846, acc: 0.00%] [G loss: 0.6808, acc: 64.58%]\n",
            "Disc pred on real: [0.5  0.5  0.63 0.5  0.5 ]\n",
            "Disc pred on fake: [0.47 0.46 0.47 0.47 0.52]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[ 0.9999249   0.99938333  1.         -0.9915323   0.00948122 -0.99697185\n",
            "   1.          0.99769425  0.99998957  1.         -1.          1.\n",
            "   0.9992596   0.99999905  0.9948272   1.          1.          0.9999998\n",
            "  -0.4497053   0.9152533  -0.9999253  -0.99593747 -0.7278013  -0.9999993\n",
            "   0.02212401  0.75247735 -0.9941228   0.69429743 -0.9757785 ]\n",
            " [-0.8449368   0.33181646 -0.8661125  -0.7867736  -0.6423035   0.7150516\n",
            "  -0.9984882  -0.91451764 -0.6647288  -0.9987429   0.9987558  -0.9951166\n",
            "   0.00238328 -0.9857645  -0.7980718  -0.9988278  -0.99571824 -0.9761474\n",
            "   0.8310935   0.16833715  0.84312963 -0.35603207 -0.6574272   0.82757246\n",
            "   0.46436286  0.9709073  -0.8155283   0.502005   -0.9783189 ]\n",
            " [ 0.99048674  0.9993995   0.99997437 -0.9806397  -0.9905245  -0.99677974\n",
            "   0.99997073  0.9966641   0.99914414  1.         -1.          0.9997092\n",
            "   0.9473739   0.99911577  0.95925987  1.          0.99998003  0.999946\n",
            "  -0.02883499  0.77567685 -0.9991837  -0.9732506  -0.3896836  -0.99985164\n",
            "   0.00980787  0.7897433  -0.9871598   0.7577619  -0.8517048 ]\n",
            " [-0.7641146  -0.99557596 -0.996185    0.9700778   0.67771566  0.6081143\n",
            "  -0.9530954  -0.00546917 -0.9842702  -0.9943767   0.9997999  -0.91832906\n",
            "  -0.6188176  -0.9810648  -0.9968155  -0.98778266 -0.9905529  -0.9653933\n",
            "  -0.05119217  0.7278021   0.93957055  0.6398071  -0.42844698  0.94941795\n",
            "  -0.53934443  0.1861652   0.977891    0.95355797  0.99805886]\n",
            " [-0.70262647  0.74041957 -0.7100591  -0.14525211 -0.6630791   0.8612796\n",
            "  -0.90225583 -0.91729945 -0.96297127 -0.9938306   0.99175924 -0.9190972\n",
            "  -0.5964771  -0.98672324 -0.95644236 -0.9686957  -0.9632365  -0.972565\n",
            "  -0.12899718  0.41801977  0.06212045  0.47877643 -0.749848    0.32879916\n",
            "   0.1900303   0.931593    0.33776313 -0.17940567  0.9237773 ]]\n",
            "250 [D loss: 0.6841, acc: 0.00%] [G loss: 0.6783, acc: 67.59%]\n",
            "Disc pred on real: [0.5  0.49 0.5  0.49 0.5 ]\n",
            "Disc pred on fake: [0.51 0.51 0.47 0.51 0.51]\n",
            "300 [D loss: 0.6831, acc: 0.00%] [G loss: 0.6771, acc: 68.96%]\n",
            "Disc pred on real: [0.49 0.49 0.5  0.5  0.49]\n",
            "Disc pred on fake: [0.5  0.5  0.48 0.48 0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.99942523  1.          1.          0.9956907  -1.          0.9990942\n",
            "   1.          0.79871535  0.54223555  1.         -1.          1.\n",
            "  -0.990614    1.          0.13494466  1.          1.          1.\n",
            "  -0.39185217 -0.85522014 -1.         -0.25644064  0.9495201  -0.99748725\n",
            "   0.7357065   0.61927277  0.997247   -0.98570406  0.9985998 ]\n",
            " [-0.11850393 -0.88886476 -0.9999699  -0.88016725 -0.7083028  -0.9987458\n",
            "  -0.995474    0.9858459  -0.9740503  -0.9997158   0.98991185 -0.99927264\n",
            "  -0.36263856 -0.9992352   0.7334333  -0.99890643 -0.9999325  -0.9958242\n",
            "  -0.93905574 -0.14126723  0.98401064  0.6775506  -0.95994025  0.99496996\n",
            "   0.99527663  0.9411324  -0.9676845   0.25566655 -0.71023387]\n",
            " [ 0.43683967 -0.8432446  -0.5877343  -0.6827325   0.99139404  0.09281132\n",
            "  -0.9788421  -0.94989896  0.07512014 -0.98722076  0.9930724  -0.8271064\n",
            "   0.9147162  -0.64087194 -0.85623515 -0.9589559  -0.42074165 -0.7009093\n",
            "   0.7012104   0.58027464  0.37750074  0.05535829 -0.84875    -0.9307693\n",
            "  -0.8021513  -0.34473678 -0.07742409  0.5888817  -0.73732823]\n",
            " [ 0.92947763 -0.6787654  -0.99930274 -0.9897847   0.9765777  -0.34342363\n",
            "  -0.99602604  0.02334103 -0.21624587 -0.9985816   0.9933569  -0.9978492\n",
            "   0.7615204  -0.9968916  -0.7126227  -0.9698956  -0.9942336  -0.9843644\n",
            "  -0.9658605   0.34051213  0.96439314  0.11644429 -0.5329364   0.40854403\n",
            "   0.9516791   0.97507524 -0.7418742  -0.87674797 -0.48933813]\n",
            " [-0.42126778 -0.34496254 -0.98366046 -0.7141614  -0.16362254  0.8341492\n",
            "  -0.9933048  -0.3352084  -0.973042   -0.9947882   0.98209715 -0.99163264\n",
            "   0.5119168  -0.9872027   0.09803264 -0.99719983 -0.99797416 -0.9466005\n",
            "   0.52544516 -0.18008682  0.65437686  0.80776846 -0.66819644 -0.21796572\n",
            "  -0.8394001  -0.71883875 -0.52106225  0.66243416  0.29892388]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 Loop:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [14:41<22:08, 442.70s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_4                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_24 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_16 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_25 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_4                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_26 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_17 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_27 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_18 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_19 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_89\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_89\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_38      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_39      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_38[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_39[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_39[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_38      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_39      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6937, acc: 0.00%] [G loss: 0.6921, acc: 53.47%]\n",
            "Disc pred on real: [0.65 0.55 0.5  0.53 0.5 ]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6888, acc: 0.00%] [G loss: 0.6890, acc: 55.25%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.49 0.48 0.51 0.49 0.51]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[-0.09078096 -0.7978044   0.9999988  -0.96258646  0.9991831  -0.3617471\n",
            "  -0.12468959 -0.9920862   0.999381    0.9999871   0.85331357  0.894863\n",
            "   0.95313215  0.9999941   0.9126925   0.9999987   0.9999412   0.9995111\n",
            "   0.5268174  -0.941622   -0.6673445  -0.25796264  0.9434125   0.8679522\n",
            "  -0.33376658 -0.44999808 -0.8037314   0.31355986  0.5815056 ]\n",
            " [-0.958157    0.8543683  -0.9264766   0.17782931 -0.73709166  0.8666894\n",
            "   0.9325577   0.6899449   0.06573332 -0.9489225  -0.76501316 -0.29654393\n",
            "   0.51517457 -0.9903863  -0.82412094 -0.9935086  -0.99096614 -0.9356049\n",
            "   0.26990208  0.9329994  -0.9886484   0.7116506   0.7000068   0.7603078\n",
            "   0.79387105  0.9762104  -0.59223175 -0.61019593 -0.13854708]\n",
            " [ 0.21512423 -0.83538795  0.99999833 -0.95393556  0.99924237  0.31731272\n",
            "   0.36030486 -0.97735125  0.99957293  0.999934    0.71595055  0.92635065\n",
            "   0.9407053   0.99999     0.8707939   0.99999547  0.99976933  0.9991223\n",
            "   0.2432109  -0.9862755  -0.4264738  -0.35033283  0.96556515  0.78323716\n",
            "   0.3219058  -0.70327276 -0.78631353  0.19833702  0.6921502 ]\n",
            " [-0.2600534  -0.80888546 -0.9949605   0.85995406 -0.8686091  -0.28209135\n",
            "  -0.8209755   0.9439174  -0.88113016 -0.6886394   0.6215102  -0.8981621\n",
            "  -0.6789826  -0.80863357  0.58611256 -0.9925117  -0.8612673   0.41880506\n",
            "  -0.15547127 -0.76661426  0.9092869   0.17538683 -0.52606213 -0.1835818\n",
            "   0.6733579   0.37585893 -0.8301618  -0.8202932   0.7383053 ]\n",
            " [ 0.5399221   0.5857497  -0.929095    0.9717165  -0.21769162 -0.05536199\n",
            "  -0.7216741   0.9788023  -0.8832108  -0.9744097   0.17669527 -0.90837646\n",
            "  -0.08365706 -0.9583099  -0.94205964 -0.98262626 -0.9686226  -0.49965233\n",
            "   0.9300288   0.72171044 -0.5677286  -0.6665625  -0.21871403 -0.7992919\n",
            "   0.8994216   0.6492168   0.15127347 -0.6297744   0.6926707 ]]\n",
            "150 [D loss: 0.6867, acc: 0.00%] [G loss: 0.6811, acc: 60.55%]\n",
            "Disc pred on real: [0.49 0.5  0.49 0.5  0.49]\n",
            "Disc pred on fake: [0.53 0.53 0.46 0.53 0.53]\n",
            "200 [D loss: 0.6862, acc: 0.00%] [G loss: 0.6757, acc: 65.91%]\n",
            "Disc pred on real: [0.63 0.5  0.5  0.5  0.51]\n",
            "Disc pred on fake: [0.53 0.52 0.51 0.51 0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.83495504  0.9998323  -0.9274806   0.7088482  -0.9972866  -0.9861187\n",
            "   0.23676638  0.99996006 -0.3257229  -0.9576829  -0.9778242  -0.5265778\n",
            "  -0.9963806   0.38835576  0.45533523 -0.31332493 -0.7477801  -0.986112\n",
            "   0.88151914  0.45033422 -0.14872205 -0.6814653  -0.99920213 -0.40224403\n",
            "   0.1582395   0.94329214 -0.7755204   0.95100117  0.8144349 ]\n",
            " [-0.7892206   0.14064541 -0.97730356  0.9827363   0.43476576  0.47144374\n",
            "  -0.9846084   0.25100714 -0.9787923  -0.99119675  0.4691539  -0.98594046\n",
            "   0.22348498 -0.9981683  -0.956501   -0.9985488  -0.9932859  -0.9675558\n",
            "   0.7814346  -0.4506513   0.17834029 -0.546902   -0.5225417  -0.70930254\n",
            "  -0.6932271   0.5669597   0.7572744   0.2941597  -0.59189874]\n",
            " [ 0.9645843  -0.99105084 -0.8296756   0.7760165   0.99818575  0.9935162\n",
            "  -0.797882   -0.9995267  -0.9078679  -0.87325877 -0.46040997 -0.6858957\n",
            "   0.97552323 -0.8635318   0.43018955 -0.9425856  -0.8539282  -0.73498935\n",
            "  -0.65946984 -0.69640505 -0.55948853 -0.09165303  0.996237   -0.7810634\n",
            "   0.7446384  -0.65885556  0.48980004 -0.7942896  -0.25045583]\n",
            " [-0.85259736 -0.75927967 -0.9658746   0.94494915  0.516289    0.76757175\n",
            "  -0.96977776 -0.41830844 -0.9904602  -0.98585135  0.69650644 -0.97950053\n",
            "  -0.26438332 -0.99396545 -0.2841886  -0.8791341  -0.98970634 -0.90085125\n",
            "   0.971494   -0.68294555 -0.8044449  -0.4732292   0.8835352  -0.6008583\n",
            "  -0.944702   -0.40261024  0.41341212 -0.83817136 -0.05524512]\n",
            " [-0.03947817 -0.83927935 -0.99588996  0.9617694   0.6487663   0.74185985\n",
            "  -0.98488396 -0.9005053  -0.9891766  -0.9124205   0.93610346 -0.99386543\n",
            "   0.75283676 -0.99772    -0.99202317 -0.9907215  -0.99769574 -0.6527106\n",
            "  -0.40993646  0.47341153 -0.20698513 -0.91393876  0.7856329   0.20657833\n",
            "   0.65409017  0.15308952  0.20428276 -0.5436636  -0.8842998 ]]\n",
            "250 [D loss: 0.6866, acc: 0.00%] [G loss: 0.6722, acc: 69.27%]\n",
            "Disc pred on real: [0.5  0.5  0.49 0.49 0.5 ]\n",
            "Disc pred on fake: [0.51 0.5  0.51 0.5  0.5 ]\n",
            "300 [D loss: 0.6866, acc: 0.00%] [G loss: 0.6710, acc: 70.88%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.5  0.49 0.49 0.5  0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[ 0.9767366   0.9999775  -0.99945724 -0.6154025  -0.9950521  -0.9981815\n",
            "   0.64637685  0.9999983  -1.          0.04945382 -0.9977429   0.9929048\n",
            "   0.5035248   0.9965685   0.62720084  0.89468867  0.98318344 -1.\n",
            "   0.6583215  -0.89529514 -0.9955162  -0.885868   -0.9998699  -0.9977872\n",
            "  -0.45239103  0.7934526   0.6217126  -0.681942    0.9848676 ]\n",
            " [-0.99388164 -0.9376936  -0.24405782  0.99224955  0.78120106  0.97067446\n",
            "  -0.9309826  -0.9988788   0.9998228  -0.99280095  0.99710315 -0.9972236\n",
            "  -0.83350426 -0.99852246 -0.02177515 -0.9900475  -0.99908155  0.9966775\n",
            "  -0.6307563   0.90881234  0.99303955  0.8389251   0.99264777  0.9391704\n",
            "   0.92993027  0.85813314  0.7324098   0.9745544  -0.9884441 ]\n",
            " [-0.49770662 -0.9999222  -0.45539778  0.7080815   0.9809014   0.9982284\n",
            "  -0.7062046  -0.9999884   0.9999428  -0.93121624  0.85333383 -0.45462978\n",
            "   0.9925237  -0.8274101  -0.88475096 -0.93940914 -0.86329395  0.99996233\n",
            "  -0.9195119   0.32960978  0.8914565   0.98414814  0.9984754   0.99688196\n",
            "   0.9383953  -0.9545697  -0.9904069   0.0964096  -0.5307952 ]\n",
            " [-0.9975646  -0.98703134  0.96919847  0.99260056  0.7542268   0.979408\n",
            "  -0.99553746 -0.99577826  0.9992697  -0.9748438   0.9885704  -0.9996124\n",
            "  -0.9710262  -0.9998942  -0.9694201  -0.9969922  -0.9998107   0.99888927\n",
            "   0.24884464  0.4597543   0.9647414  -0.8486272   0.9790841   0.97239244\n",
            "   0.7918441   0.8232435   0.9736414   0.9923758  -0.9999217 ]\n",
            " [-0.9556803  -0.95676744 -0.8427925   0.9846282   0.92838484  0.04071406\n",
            "  -0.9736981  -0.4793981   0.85787946 -0.9705879   0.9969491  -0.9952288\n",
            "   0.66455734 -0.9969334  -0.8928912  -0.9885628  -0.9949951   0.94335866\n",
            "  -0.48523372  0.3114523   0.93347085  0.8188547   0.9682155   0.9740639\n",
            "   0.80989766  0.07692251 -0.5968598   0.8799454  -0.77501464]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 Loop:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [21:46<14:29, 434.54s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_5                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_20 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_5                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_32 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_21 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_33 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_22 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_34 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_23 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_35 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_15          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_107\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_107\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_46      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_47      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_46[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_47[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_47[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_46      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_47      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6950, acc: 0.00%] [G loss: 0.6897, acc: 65.72%]\n",
            "Disc pred on real: [0.51 0.5  0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6933, acc: 0.00%] [G loss: 0.6860, acc: 67.59%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.49 0.49 0.49 0.49 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[ 0.9999995  -0.9958696   0.9998745  -0.99922657  0.9999975   0.73999065\n",
            "   0.99999774  0.9601136   0.9998278   1.         -0.99999774  0.9792074\n",
            "   0.60069895  0.99218804 -0.99967915  0.9636215   0.99764985 -0.92756456\n",
            "  -0.9999985   0.00884802 -0.7928338   0.96279204  0.58379805  0.60552365\n",
            "  -0.89730585  0.6468183   0.7978864   0.99647766  0.9498085 ]\n",
            " [-0.99035007  0.9942495  -0.9767223   0.99786764 -0.9857129  -0.68181735\n",
            "  -0.98148066 -0.6070566  -0.99787575 -0.9834937   0.9995359  -0.9869568\n",
            "  -0.21450862 -0.9940982   0.9377556   0.46476188 -0.9752664  -0.9440093\n",
            "   0.9882678  -0.4120409   0.9035878  -0.23295906  0.06392304 -0.8217244\n",
            "   0.8132107   0.7180426   0.31660202 -0.9038426  -0.7628881 ]\n",
            " [ 0.99786246 -0.9540446   0.8047308  -0.01926456  0.2862656  -0.9320184\n",
            "   0.8230872   0.77490604  0.9846533   0.12548478 -0.98697305  0.56765854\n",
            "   0.9796798  -0.75750965  0.9665084  -0.13947761 -0.7766093  -0.9784846\n",
            "   0.8830243   0.5930338  -0.6296138   0.53970647  0.85349894 -0.1836357\n",
            "  -0.97844905  0.21740304 -0.87595755  0.4466053   0.9565822 ]\n",
            " [-0.906141    0.9920449  -0.9942154   0.9907438  -0.82704204 -0.6300913\n",
            "  -0.966659   -0.313613   -0.98717165 -0.98202264  0.9946182  -0.92083436\n",
            "  -0.5764677  -0.9871265   0.86941224  0.21751219 -0.9036186  -0.9799127\n",
            "   0.9521154   0.23747267  0.85433143  0.3054266   0.29494354 -0.82854325\n",
            "   0.3693616   0.15199605  0.5610275  -0.76428944 -0.6437678 ]\n",
            " [-0.9960721   0.9964058  -0.9801812   0.995982   -0.9940192  -0.67898697\n",
            "  -0.990495   -0.6922392  -0.9958022  -0.97406197  0.9995151  -0.98709434\n",
            "   0.00871537 -0.98925847  0.90643436  0.50542426 -0.90933657 -0.9263068\n",
            "   0.9857293  -0.04470004  0.9634395  -0.4800055  -0.46375465 -0.95854056\n",
            "   0.7176433   0.81197214 -0.14340867 -0.8991736  -0.82247543]]\n",
            "150 [D loss: 0.6908, acc: 0.00%] [G loss: 0.6793, acc: 68.35%]\n",
            "Disc pred on real: [0.5  0.49 0.49 0.85 0.5 ]\n",
            "Disc pred on fake: [0.52 0.52 0.49 0.53 0.52]\n",
            "200 [D loss: 0.6896, acc: 0.00%] [G loss: 0.6746, acc: 69.56%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.49 0.5 ]\n",
            "Disc pred on fake: [0.49 0.5  0.49 0.5  0.5 ]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[ 0.92831993  0.8443372   0.9467962  -0.9949225  -0.60764974 -0.40808174\n",
            "  -0.7369363  -0.9327844   0.8156834   0.9934864  -0.4987073   0.9113767\n",
            "  -0.7169628   0.9591753   0.9051379  -0.81023777  0.81443125  0.998232\n",
            "   0.99881786  0.71268153 -0.8595007   0.18506257 -0.5989457  -0.03264845\n",
            "   0.891745   -0.7691195   0.78340346  0.6996397   0.37958947]\n",
            " [-0.969905    0.887712   -0.9917881   0.9908947  -0.8132856  -0.9562179\n",
            "  -0.95944846  0.64896977 -0.9632591  -0.9972656   0.9934821  -0.99476945\n",
            "   0.2821273  -0.99886286  0.822193   -0.68994075 -0.99678236 -0.97792035\n",
            "   0.12247642  0.00844788  0.9443648  -0.49296635 -0.14146172 -0.8404897\n",
            "   0.3356367   0.47562787 -0.503737   -0.8831196   0.87807447]\n",
            " [ 0.99902195 -0.9999077   0.9999534  -0.9997339   0.22664872  0.7539251\n",
            "   1.         -0.9938491   0.15117349  0.8738616  -0.9999982   0.999997\n",
            "   0.35429156  0.99991465 -0.42424467  0.86453795  0.9999849   0.9992409\n",
            "  -0.98939276  0.95599025 -0.7696362  -0.8792263  -0.1850948  -0.75806284\n",
            "   0.14993165 -0.78647554  0.8238248   0.81045103 -0.5154632 ]\n",
            " [-0.9658053   0.87308896 -0.9907164   0.991934   -0.8154059  -0.94023\n",
            "  -0.96372044  0.6822968  -0.9715986  -0.99706537  0.9936191  -0.99409384\n",
            "   0.28415647 -0.99845904  0.7741218  -0.68933237 -0.9977272  -0.9750185\n",
            "   0.05903171  0.04278759  0.939556   -0.50258976  0.17324916 -0.8703581\n",
            "   0.26563478  0.6004893  -0.45145026 -0.91695505  0.8584027 ]\n",
            " [-0.97296923  0.85987127 -0.98915875  0.99117464 -0.84405524 -0.9405549\n",
            "  -0.9580197   0.7159655  -0.9708191  -0.99704015  0.99314755 -0.99315584\n",
            "   0.3166008  -0.9985221   0.758036   -0.73406893 -0.99749845 -0.96874183\n",
            "  -0.05551524  0.12616248  0.93809384 -0.5295617   0.09805202 -0.8331346\n",
            "   0.13761595  0.61548615 -0.34287733 -0.9195716   0.8493496 ]]\n",
            "250 [D loss: 0.6885, acc: 0.00%] [G loss: 0.6725, acc: 69.16%]\n",
            "Disc pred on real: [0.75 0.5  0.49 0.49 0.5 ]\n",
            "Disc pred on fake: [0.54 0.5  0.49 0.49 0.5 ]\n",
            "300 [D loss: 0.6875, acc: 0.00%] [G loss: 0.6719, acc: 67.79%]\n",
            "Disc pred on real: [0.49 0.49 0.49 0.49 0.49]\n",
            "Disc pred on fake: [0.49 0.49 0.49 0.49 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[ 0.45207402 -0.99509853  0.11506304 -0.93502486 -0.37809202 -0.86363184\n",
            "   0.99987525  0.11339714 -0.37257645 -0.8084787  -0.9912918   0.9992913\n",
            "  -0.06887981 -0.13018894  0.5919224   0.744048    0.97495127  0.9989525\n",
            "   0.7832345  -0.29218483  0.7808616   0.9001758   0.5917079  -0.9830186\n",
            "  -0.98704374 -0.7806653  -0.3820442   0.9538118  -0.65173006]\n",
            " [ 0.97108364  0.21757522 -0.99758494  0.99544036 -0.8366389  -0.86616474\n",
            "  -0.9970611   0.1045365  -0.94919646 -0.9999756   0.9994442  -0.9999451\n",
            "  -0.16380353 -0.9999842   0.88222885 -0.9900839  -0.9999478  -0.993568\n",
            "   0.8615186   0.37623265 -0.94597185 -0.06089864 -0.13612029  0.71106744\n",
            "   0.8052624   0.8471656   0.5929409  -0.99323523  0.9740934 ]\n",
            " [-0.42163488 -0.816932   -0.8963092   0.56542325 -0.73458195 -0.7504439\n",
            "   0.5388883  -0.8519481  -0.9514637  -0.98300624  0.61395115 -0.4474897\n",
            "  -0.43132704 -0.87739635  0.3920985  -0.39646283 -0.82281137 -0.6412342\n",
            "   0.6176681  -0.26700574  0.5558871   0.48890752 -0.27175397 -0.8873993\n",
            "   0.40183812 -0.297626    0.40402552  0.657258   -0.04141202]\n",
            " [ 0.96850085  0.14828047 -0.997942    0.99617386 -0.81576765 -0.86323667\n",
            "  -0.9975638   0.09099657 -0.94576615 -0.99997026  0.99950325 -0.99994946\n",
            "  -0.16485871 -0.999986    0.8767612  -0.99224263 -0.99994195 -0.99357677\n",
            "   0.84712166  0.32220826 -0.94206923 -0.11802451 -0.17354462  0.7015531\n",
            "   0.7706739   0.8357737   0.47351304 -0.9937854   0.9776545 ]\n",
            " [ 0.9697401   0.19429399 -0.9978294   0.99630576 -0.868936   -0.85886717\n",
            "  -0.99712384  0.15248172 -0.9432573  -0.9999741   0.9995513  -0.9999515\n",
            "  -0.02594823 -0.9999865   0.88120997 -0.9911857  -0.99995476 -0.99278855\n",
            "   0.8587221   0.44240308 -0.93445176 -0.13912396 -0.26808822  0.71114326\n",
            "   0.8117177   0.8134032   0.5240512  -0.99313146  0.9755012 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExperiment 1 Loop:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [29:49<07:33, 453.83s/it]/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_6                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_24 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise_6                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)                 â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_38 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_25 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_39 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_26 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_40 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_27 (\u001b[38;5;33mLeakyReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_41 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_125\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_125\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_54      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_55      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_54[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_55[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_55[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_54      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_55      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6951, acc: 0.00%] [G loss: 0.6906, acc: 58.81%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.5 0.5 0.5 0.5 0.5]\n",
            "100 [D loss: 0.6914, acc: 0.00%] [G loss: 0.6853, acc: 62.36%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.49 0.52 0.49 0.51 0.48]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[-0.24721296  0.6047455  -0.9675831   0.5794754   0.35580713 -0.3141602\n",
            "   0.7262453   0.88023263  0.9028223   0.28208378  0.11111955 -0.91784024\n",
            "   0.6109641   0.066486   -0.46820125 -0.6881753  -0.93829256 -0.5988894\n",
            "  -0.6027158  -0.49023727 -0.6622781   0.70332164 -0.10955013  0.91080296\n",
            "   0.97711533  0.48518738  0.61492676 -0.8513825   0.99008614]\n",
            " [-0.9891121   0.950189   -0.98556936  0.9839351  -0.97162765  0.9260606\n",
            "  -0.96486044  0.69310975 -0.9758224  -0.99125266  0.9865766  -0.99004656\n",
            "  -0.6458096  -0.97984684  0.77074164 -0.99233013 -0.9648779  -0.9499876\n",
            "  -0.8662299  -0.7558791   0.95796895 -0.6590487   0.9942243   0.75344163\n",
            "  -0.3661478   0.06651952  0.51857704 -0.20949481  0.02431102]\n",
            " [ 0.91636586  0.998244   -0.9990524  -0.30917847  0.9783071  -0.7266485\n",
            "  -0.6505055   0.5659615  -0.9999626  -0.927125   -0.8205882  -0.9999202\n",
            "   0.9274088  -0.99319595 -0.07254616  0.93417954 -0.99999446 -0.99795437\n",
            "  -0.97441334 -0.95124084  0.7755949   0.88812405 -0.9781828  -0.99849224\n",
            "  -0.88483244 -0.65789956  0.6322505  -0.85307884 -0.09563542]\n",
            " [-0.98187155  0.92827666 -0.9769038   0.9896276  -0.9746054   0.9181663\n",
            "  -0.98306185  0.8196026  -0.9495405  -0.9953783   0.9862265  -0.9806742\n",
            "  -0.8040132  -0.978576    0.74991024 -0.98606247 -0.9433949  -0.975575\n",
            "  -0.8719866  -0.9385521   0.93686634 -0.6781232   0.9921874   0.30339995\n",
            "  -0.5067489  -0.11258449  0.35596624 -0.32764846 -0.45157015]\n",
            " [-0.99296     0.9609822  -0.97585505  0.9760769  -0.9830328   0.90363\n",
            "  -0.9868882   0.9066631  -0.9608542  -0.9902976   0.9948054  -0.9744095\n",
            "  -0.8613428  -0.9797782   0.43352002 -0.981748   -0.97819054 -0.96012825\n",
            "  -0.91152877 -0.9281753   0.98131424 -0.8247491   0.9923789   0.62728214\n",
            "  -0.42432353 -0.13926403  0.69887805 -0.3713656  -0.23138712]]\n",
            "150 [D loss: 0.6901, acc: 0.00%] [G loss: 0.6787, acc: 65.71%]\n",
            "Disc pred on real: [0.5 0.5 0.5 0.5 0.5]\n",
            "Disc pred on fake: [0.51 0.49 0.5  0.5  0.51]\n",
            "200 [D loss: 0.6890, acc: 0.00%] [G loss: 0.6758, acc: 67.05%]\n",
            "Disc pred on real: [0.5  0.64 0.5  0.5  0.62]\n",
            "Disc pred on fake: [0.5  0.53 0.49 0.49 0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.9261986   0.99489635 -0.9996642   0.9926496   0.77451724 -0.3120151\n",
            "  -0.9994309  -0.9914766  -0.9973152  -0.99956846  0.9948009  -0.99150753\n",
            "   0.11995677 -0.9984407   0.61187273 -0.9998576  -0.998441   -0.9412931\n",
            "  -0.73988324 -0.9471596   0.60704     0.43236458 -0.89694506 -0.87455547\n",
            "   0.00352974  0.07510525  0.44604897 -0.04303171  0.60322493]\n",
            " [-0.3083129   0.94238645 -0.99547523  0.98619807  0.7098981  -0.5511147\n",
            "  -0.9921368  -0.92786974 -0.93616694 -0.99801075  0.9943851  -0.99881077\n",
            "  -0.30014405 -0.99884856  0.8523892  -0.9927357  -0.996663   -0.94968694\n",
            "  -0.95637614  0.27211457 -0.8852717   0.9765001  -0.9788099  -0.02878654\n",
            "   0.5662529  -0.14456381  0.17795092 -0.7828474   0.27677354]\n",
            " [ 0.2828387  -0.9999931   1.         -0.9999995  -0.9944236  -0.59397006\n",
            "   0.9999993   0.99904966  1.          1.         -0.9999761   1.\n",
            "   0.8439899   1.         -0.9104021   1.          1.          0.999963\n",
            "   0.9054876   0.39790103 -0.93346995 -0.95191884  0.4339147   0.72886884\n",
            "  -0.39456022 -0.868212   -0.9610515  -0.9279601  -0.46973988]\n",
            " [-0.47227943  0.9271507  -0.99569935  0.9817299   0.6808935  -0.4711924\n",
            "  -0.99178284 -0.92685616 -0.93044    -0.9978827   0.99366885 -0.99870807\n",
            "  -0.28712347 -0.99911267  0.8778578  -0.99194765 -0.99531305 -0.9408543\n",
            "  -0.9589037   0.4766837  -0.86167276  0.9825811  -0.97610295 -0.12430438\n",
            "   0.6313812  -0.217348    0.04274603 -0.78417206  0.4204149 ]\n",
            " [-0.4634603   0.9502543  -0.99523085  0.98267096  0.68569666 -0.56504285\n",
            "  -0.991827   -0.91668105 -0.9398273  -0.9973654   0.9942897  -0.9985352\n",
            "  -0.3927118  -0.9990512   0.82148045 -0.99256986 -0.99520457 -0.95421505\n",
            "  -0.9394761   0.57735425 -0.8632535   0.98640096 -0.95551014 -0.15093562\n",
            "   0.54307514 -0.18484701  0.0308267  -0.7715945   0.48367977]]\n",
            "250 [D loss: 0.6890, acc: 0.00%] [G loss: 0.6749, acc: 66.77%]\n",
            "Disc pred on real: [0.49 0.49 0.5  0.5  0.5 ]\n",
            "Disc pred on fake: [0.5  0.49 0.49 0.5  0.5 ]\n",
            "300 [D loss: 0.6878, acc: 0.00%] [G loss: 0.6755, acc: 65.47%]\n",
            "Disc pred on real: [0.49 0.49 0.49 0.49 0.84]\n",
            "Disc pred on fake: [0.49 0.5  0.49 0.49 0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.74142635  0.9979936  -0.9997126   0.97872305  0.8538523  -0.02011397\n",
            "  -0.99235487 -0.93997204 -0.9947365  -0.9999074   0.99814624 -0.99795455\n",
            "   0.87520045 -0.99437696 -0.41909167 -0.99974614 -0.9992028   0.8088348\n",
            "   0.98808426 -0.5929417   0.9850309   0.7902701  -0.9561964  -0.80740285\n",
            "   0.55405253  0.9895443  -0.9153078   0.48033223 -0.10036045]\n",
            " [ 0.7691857  -0.6185133  -0.9940031   0.996578   -0.81362545 -0.6172749\n",
            "  -0.99710333 -0.5298948   0.60866594 -0.99747765  0.99500906 -0.9998362\n",
            "   0.84970105 -0.9999136  -0.7199784  -0.9982063  -0.9985255   0.7940961\n",
            "   0.2422338   0.90203655  0.89840764 -0.9685698  -0.9925045   0.5419388\n",
            "   0.9261438   0.6925718   0.42432186 -0.6396556   0.9087813 ]\n",
            " [-0.7095591  -0.7758624  -0.9999618   0.9584871   0.7497987   0.9318264\n",
            "  -0.9992343  -0.9938329  -0.99996305 -0.9997291   0.9958863  -0.22082303\n",
            "   0.13575082 -0.76332176  0.9312378  -0.99652964 -0.99982476  0.9971171\n",
            "   0.974311   -0.35438353  0.79509985  0.9857532  -0.999739   -0.8066555\n",
            "  -0.18075417  0.9437338  -0.21106751  0.31059954  0.2454503 ]\n",
            " [ 0.77757937 -0.77346534 -0.9946416   0.9967845  -0.7852942  -0.64717674\n",
            "  -0.99651605 -0.6344444   0.5462832  -0.9975357   0.9942664  -0.99973613\n",
            "   0.8569519  -0.99975914 -0.5992805  -0.99749464 -0.998122    0.8238129\n",
            "   0.31924585  0.8569773   0.8474872  -0.9702648  -0.99631715  0.3698636\n",
            "   0.9542929   0.6847171   0.54047066 -0.6187394   0.93664306]\n",
            " [ 0.7719133  -0.716276   -0.9944517   0.9967984  -0.82319826 -0.6744833\n",
            "  -0.99656725 -0.4887782   0.569442   -0.9971631   0.9945592  -0.9997967\n",
            "   0.8663595  -0.9998864  -0.7308332  -0.9976886  -0.9982929   0.83684456\n",
            "   0.3997489   0.85181546  0.91795367 -0.9819397  -0.995793    0.47696808\n",
            "   0.9465508   0.69948256  0.5304928  -0.5735242   0.9135915 ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Experiment 1 Loop: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [37:49<00:00, 453.98s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dfb1f9a"
      },
      "source": [
        "\n",
        "\n",
        "*   As the percentage of fraud training data used to train the GAN increases from 0.01% to 1.0%, there is a general upward trend observed in all three classifier performance metrics: ROC-AUC, PR-AUC, and F1-score.\n",
        "*   Training the GAN with a larger proportion of the available fraud data appears to result in the generation of more effective synthetic data, which subsequently enhances the classifier's ability to differentiate between fraudulent and non-fraudulent transactions on the test set.\n"
      ],
      "id": "5dfb1f9a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referneces-[A hybrid deep learning approach with generative adversarial network for credit card fraud detection](https://doi.org/10.3390/technologies12100186), [Improving detection of credit card fraudulent transactions using generative adversarial networks](https://arxiv.org/abs/1907.03355), [Generative adversarial network for oversampling data in credit card fraud detection](https://link.springer.com/chapter/10.1007/978-3-030-36945-3_7), https://www.kaggle.com/code/gauravduttakiit/cc-fraud-detection-gan-random-forest-classifier/data"
      ],
      "metadata": {
        "id": "ATIleW08Io-D"
      },
      "id": "ATIleW08Io-D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note- ChatGPT used for understanding results and solving errors in the discriminator of cgan."
      ],
      "metadata": {
        "id": "hz01Twt5Iq4v"
      },
      "id": "hz01Twt5Iq4v"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 310,
          "sourceId": 23498,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30822,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1846.66889,
      "end_time": "2024-12-30T03:00:04.367340",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-30T02:29:17.698450",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}