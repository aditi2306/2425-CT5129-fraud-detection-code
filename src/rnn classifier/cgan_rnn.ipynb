{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CGAN with RNN as classifier"
      ],
      "metadata": {
        "id": "kUqw4rzHk_yw"
      },
      "id": "kUqw4rzHk_yw"
    },
    {
      "cell_type": "markdown",
      "id": "95b87982",
      "metadata": {
        "id": "95b87982"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2d1424",
      "metadata": {
        "id": "cb2d1424"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,\\\n",
        "                            accuracy_score, balanced_accuracy_score,classification_report,\\\n",
        "                            confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QgenRhZYJcmv",
      "metadata": {
        "id": "QgenRhZYJcmv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90a60195",
      "metadata": {
        "id": "90a60195"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79bf21d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bf21d7",
        "outputId": "88268020-31be-4f1d-8b3d-f7a5434eebe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      284807 non-null  float64\n",
            " 1   V2      284807 non-null  float64\n",
            " 2   V3      284807 non-null  float64\n",
            " 3   V4      284807 non-null  float64\n",
            " 4   V5      284807 non-null  float64\n",
            " 5   V6      284807 non-null  float64\n",
            " 6   V7      284807 non-null  float64\n",
            " 7   V8      284807 non-null  float64\n",
            " 8   V9      284807 non-null  float64\n",
            " 9   V10     284807 non-null  float64\n",
            " 10  V11     284807 non-null  float64\n",
            " 11  V12     284807 non-null  float64\n",
            " 12  V13     284807 non-null  float64\n",
            " 13  V14     284807 non-null  float64\n",
            " 14  V15     284807 non-null  float64\n",
            " 15  V16     284807 non-null  float64\n",
            " 16  V17     284807 non-null  float64\n",
            " 17  V18     284807 non-null  float64\n",
            " 18  V19     284807 non-null  float64\n",
            " 19  V20     284807 non-null  float64\n",
            " 20  V21     284807 non-null  float64\n",
            " 21  V22     284807 non-null  float64\n",
            " 22  V23     284807 non-null  float64\n",
            " 23  V24     284807 non-null  float64\n",
            " 24  V25     284807 non-null  float64\n",
            " 25  V26     284807 non-null  float64\n",
            " 26  V27     284807 non-null  float64\n",
            " 27  V28     284807 non-null  float64\n",
            " 28  Amount  284807 non-null  float64\n",
            " 29  Class   284807 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv('./creditcard.csv')\n",
        "df=df.drop('Time',axis=1)\n",
        "df.head()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a828e2f8",
      "metadata": {
        "id": "a828e2f8"
      },
      "source": [
        "PCA Transformation: The description of the data says that all the features went through a PCA transformation (Except for time and amount).  \n",
        "Scaling: Keep in mind that in order to implement a PCA transformation features need to be previously scaled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b13394f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "b13394f3",
        "outputId": "39b35030-b91b-4d35-b2b8-c0003e685902"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 V1            V2            V3            V4            V5  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15  9.604066e-16   \n",
              "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
              "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
              "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
              "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
              "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
              "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
              "\n",
              "                 V6            V7            V8            V9           V10  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15  2.239053e-15   \n",
              "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
              "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
              "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
              "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
              "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
              "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e4a2970-f7e9-4578-bf2e-96184562a302\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>2.239053e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4a2970-f7e9-4578-bf2e-96184562a302')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e4a2970-f7e9-4578-bf2e-96184562a302 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e4a2970-f7e9-4578-bf2e-96184562a302');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-162d7be5-a2d4-4d46-adb4-8adf56978170\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-162d7be5-a2d4-4d46-adb4-8adf56978170')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-162d7be5-a2d4-4d46-adb4-8adf56978170 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306b3e6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "306b3e6f",
        "outputId": "b5036aec-abdb-4b8e-cf04-5b3dd3229458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 9144 duplicate rows\n"
          ]
        }
      ],
      "source": [
        "# checking for duplicate values\n",
        "print(f\"Dataset has {df.duplicated().sum()} duplicate rows\")\n",
        "# dropping duplicate rows\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2f4c06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b2f4c06",
        "outputId": "44da054e-2e13-4a3a-9546-0267024b7bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 275663 entries, 0 to 284806\n",
            "Data columns (total 30 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   V1      275663 non-null  float64\n",
            " 1   V2      275663 non-null  float64\n",
            " 2   V3      275663 non-null  float64\n",
            " 3   V4      275663 non-null  float64\n",
            " 4   V5      275663 non-null  float64\n",
            " 5   V6      275663 non-null  float64\n",
            " 6   V7      275663 non-null  float64\n",
            " 7   V8      275663 non-null  float64\n",
            " 8   V9      275663 non-null  float64\n",
            " 9   V10     275663 non-null  float64\n",
            " 10  V11     275663 non-null  float64\n",
            " 11  V12     275663 non-null  float64\n",
            " 12  V13     275663 non-null  float64\n",
            " 13  V14     275663 non-null  float64\n",
            " 14  V15     275663 non-null  float64\n",
            " 15  V16     275663 non-null  float64\n",
            " 16  V17     275663 non-null  float64\n",
            " 17  V18     275663 non-null  float64\n",
            " 18  V19     275663 non-null  float64\n",
            " 19  V20     275663 non-null  float64\n",
            " 20  V21     275663 non-null  float64\n",
            " 21  V22     275663 non-null  float64\n",
            " 22  V23     275663 non-null  float64\n",
            " 23  V24     275663 non-null  float64\n",
            " 24  V25     275663 non-null  float64\n",
            " 25  V26     275663 non-null  float64\n",
            " 26  V27     275663 non-null  float64\n",
            " 27  V28     275663 non-null  float64\n",
            " 28  Amount  275663 non-null  float64\n",
            " 29  Class   275663 non-null  int64  \n",
            "dtypes: float64(29), int64(1)\n",
            "memory usage: 65.2 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5128908",
      "metadata": {
        "id": "c5128908"
      },
      "source": [
        "There is no null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6c996a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d6c996a",
        "outputId": "568932c3-8e6e-43da-a4d5-9e320b6b74f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Frauds 99.83 % of the dataset\n",
            "Frauds 0.17 % of the dataset\n"
          ]
        }
      ],
      "source": [
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d88ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "d88ad047",
        "outputId": "694b4f54-f612-4866-ffb1-e89267ee5c29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Class', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.countplot(data=df,x='Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30728ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "30728ee8",
        "outputId": "0c220ead-9d84-4a7c-aff1-7581d83e2b59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "V1        -3.273070\n",
              "V2        -4.653486\n",
              "V3        -2.216730\n",
              "V4         0.681387\n",
              "V5        -2.458790\n",
              "V6         1.867576\n",
              "V7         2.877722\n",
              "V8        -8.292631\n",
              "V9         0.550965\n",
              "V10        1.242165\n",
              "V11        0.347772\n",
              "V12       -2.208171\n",
              "V13        0.061058\n",
              "V14       -1.953613\n",
              "V15       -0.295836\n",
              "V16       -1.048371\n",
              "V17       -3.802987\n",
              "V18       -0.255710\n",
              "V19        0.115957\n",
              "V20       -2.045060\n",
              "V21        2.784302\n",
              "V22       -0.200868\n",
              "V23       -5.805236\n",
              "V24       -0.545636\n",
              "V25       -0.408260\n",
              "V26        0.587603\n",
              "V27       -0.745732\n",
              "V28       11.400938\n",
              "Amount    16.841622\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>V1</th>\n",
              "      <td>-3.273070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V2</th>\n",
              "      <td>-4.653486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V3</th>\n",
              "      <td>-2.216730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V4</th>\n",
              "      <td>0.681387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V5</th>\n",
              "      <td>-2.458790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V6</th>\n",
              "      <td>1.867576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V7</th>\n",
              "      <td>2.877722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V8</th>\n",
              "      <td>-8.292631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V9</th>\n",
              "      <td>0.550965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V10</th>\n",
              "      <td>1.242165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V11</th>\n",
              "      <td>0.347772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V12</th>\n",
              "      <td>-2.208171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V13</th>\n",
              "      <td>0.061058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V14</th>\n",
              "      <td>-1.953613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V15</th>\n",
              "      <td>-0.295836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V16</th>\n",
              "      <td>-1.048371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V17</th>\n",
              "      <td>-3.802987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V18</th>\n",
              "      <td>-0.255710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V19</th>\n",
              "      <td>0.115957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V20</th>\n",
              "      <td>-2.045060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V21</th>\n",
              "      <td>2.784302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V22</th>\n",
              "      <td>-0.200868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V23</th>\n",
              "      <td>-5.805236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V24</th>\n",
              "      <td>-0.545636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V25</th>\n",
              "      <td>-0.408260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V26</th>\n",
              "      <td>0.587603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V27</th>\n",
              "      <td>-0.745732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V28</th>\n",
              "      <td>11.400938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Amount</th>\n",
              "      <td>16.841622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.drop('Class',axis=1).skew()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85bb3774",
      "metadata": {
        "id": "85bb3774"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab1142e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ab1142e",
        "outputId": "b6843d73-aa78-4d30-c1d0-3dfcff240bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(275663, 29) (275663,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df.drop('Class', axis=1))\n",
        "y = df['Class'].values\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e31517",
      "metadata": {
        "id": "22e31517"
      },
      "source": [
        "## Splitting the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fa74b00",
      "metadata": {
        "id": "6fa74b00"
      },
      "source": [
        "we want to test our models on the original testing set not on the testing set created from GAN. The main goal is to fit the model in the generated data, and test it on the original testing set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8303d35",
      "metadata": {
        "id": "f8303d35"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1beefe0",
      "metadata": {
        "id": "e1beefe0"
      },
      "source": [
        "## Testing baseline model with original data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50b98b70",
      "metadata": {
        "id": "50b98b70"
      },
      "source": [
        "## Conditional GAN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, multiply, LeakyReLU, Dropout, BatchNormalization, GaussianNoise\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class cGAN():\n",
        "    def __init__(self):\n",
        "        self.latent_dim = 32\n",
        "        self.out_shape = 29\n",
        "        self.num_classes = 2\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,))\n",
        "        gen_samples = self.generator([noise, label])\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "        valid = self.discriminator([gen_samples, label])\n",
        "\n",
        "        self.combined = Model([noise, label], valid)\n",
        "        self.combined.compile(loss='binary_crossentropy',\n",
        "                              optimizer=Adam(0.0002, 0.5),\n",
        "                              metrics=['accuracy'])\n",
        "        self.combined.summary()\n",
        "\n",
        "    def build_generator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128, input_dim=self.latent_dim))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(256))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Dense(512))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(self.out_shape, activation='tanh'))\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
        "        model_input = multiply([noise, label_embedding])\n",
        "        gen_sample = model(model_input)\n",
        "\n",
        "        return Model([noise, label], gen_sample, name=\"Generator\")\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(GaussianNoise(0.1, input_shape=(self.out_shape,)))\n",
        "        model.add(Dense(256, kernel_initializer=init, kernel_regularizer=l2(0.001)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.summary()\n",
        "\n",
        "        gen_sample = Input(shape=(self.out_shape,))\n",
        "        label = Input(shape=(1,), dtype='int32')\n",
        "        label_embedding = Flatten()(Embedding(self.num_classes, self.out_shape)(label))\n",
        "        model_input = multiply([gen_sample, label_embedding])\n",
        "        validity = model(model_input)\n",
        "\n",
        "        return Model([gen_sample, label], validity, name=\"Discriminator\")\n",
        "\n",
        "    def train(self, X_train, y_train, pos_index, neg_index, epochs, batch_size=32, sample_interval=50):\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # === Train Discriminator ===\n",
        "            idx1 = np.random.choice(pos_index, 8)\n",
        "            idx0 = np.random.choice(neg_index, batch_size - 8)\n",
        "            idx = np.concatenate((idx1, idx0))\n",
        "            samples, labels = X_train[idx], y_train[idx]\n",
        "            samples, labels = shuffle(samples, labels)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_samples = self.generator.predict([noise, labels], verbose=0)\n",
        "\n",
        "            valid_smooth = np.random.uniform(low=0.9, high=1.0, size=(batch_size, 1))\n",
        "            fake_smooth = np.random.uniform(low=0.0, high=0.1, size=(batch_size, 1))\n",
        "\n",
        "            if np.random.rand() < 0.05:\n",
        "                valid_smooth, fake_smooth = fake_smooth, valid_smooth\n",
        "\n",
        "            self.discriminator.trainable = True\n",
        "            d_loss_real = self.discriminator.train_on_batch([samples, labels], valid_smooth)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([gen_samples, labels], fake_smooth)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # === Train Generator ===\n",
        "            self.discriminator.trainable = False\n",
        "            sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
        "\n",
        "\n",
        "            if (epoch + 1) % sample_interval == 0:\n",
        "                print(f\"{epoch + 1} [D loss: {d_loss[0]:.4f}, acc: {100*d_loss[1]:.2f}%] \"\n",
        "                      f\"[G loss: {g_loss[0]:.4f}, acc: {100*g_loss[1]:.2f}%]\")\n",
        "\n",
        "                d_real_pred = self.discriminator.predict([samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                d_fake_pred = self.discriminator.predict([gen_samples[:5], labels[:5]], verbose=0).flatten()\n",
        "                print(\"Disc pred on real:\", np.round(d_real_pred, 2))\n",
        "                print(\"Disc pred on fake:\", np.round(d_fake_pred, 2))\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                self.save_generated_samples(epoch + 1)\n",
        "\n",
        "    def save_generated_samples(self, epoch):\n",
        "        noise = np.random.normal(0, 1, (5, self.latent_dim))\n",
        "        labels = np.array([[0], [1], [0], [1], [1]])\n",
        "        gen_samples = self.generator.predict([noise, labels])\n",
        "        print(f\"Generated samples at epoch {epoch}:\\n{gen_samples}\")"
      ],
      "metadata": {
        "id": "zL2u47WRNTOr"
      },
      "id": "zL2u47WRNTOr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0bbcfd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3d0bbcfd",
        "outputId": "4cda2dc5-a1d0-4645-ec81-b1dac36cb808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/regularization/gaussian_noise.py:29: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning:\n",
            "\n",
            "Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise (\u001b[38;5;33mGaussianNoise\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m7,680\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m257\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gaussian_noise (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,680</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,937\u001b[0m (31.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,937</span> (31.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
            "\n",
            "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚        \u001b[38;5;34m33,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚       \u001b[38;5;34m131,584\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             â”‚        \u001b[38;5;34m14,877\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,293\u001b[0m (731.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,293</span> (731.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,501\u001b[0m (724.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,501</span> (724.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,792\u001b[0m (7.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> (7.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_6       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_7       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)        â”‚    \u001b[38;5;34m187,357\u001b[0m â”‚ input_layer_6[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚      \u001b[38;5;34m7,995\u001b[0m â”‚ Generator[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚                   â”‚            â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_6       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_7       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Generator           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)        â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">187,357</span> â”‚ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ Discriminator       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,995</span> â”‚ Generator[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚                   â”‚            â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,352\u001b[0m (763.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,352</span> (763.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m185,565\u001b[0m (724.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,565</span> (724.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,787\u001b[0m (38.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,787</span> (38.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "cgan = cGAN()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d2d7879",
      "metadata": {
        "id": "2d2d7879"
      },
      "source": [
        "## Training GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c286d31",
      "metadata": {
        "id": "6c286d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01c18f4-e63e-4a56-a428-6b485d6180ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning:\n",
            "\n",
            "Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 [D loss: 0.6913, acc: 0.00%] [G loss: 0.6916, acc: 54.75%]\n",
            "Disc pred on real: [0.51 0.58 0.5  0.5  0.56]\n",
            "Disc pred on fake: [0.51 0.51 0.5  0.5  0.51]\n",
            "100 [D loss: 0.6875, acc: 0.00%] [G loss: 0.6846, acc: 61.50%]\n",
            "Disc pred on real: [0.5  0.5  0.5  0.63 0.69]\n",
            "Disc pred on fake: [0.49 0.49 0.49 0.53 0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "Generated samples at epoch 100:\n",
            "[[-0.7110281  -0.29107115  0.9779237   0.5178863   0.46045187  0.23785146\n",
            "   0.92072517  0.06022343  0.8262219   0.80953735  0.99110246 -0.8618632\n",
            "   0.20356463 -0.99368817 -0.54439443  0.40772766  0.9301809  -0.89147085\n",
            "   0.46238446  0.93422854 -0.96347886  0.5584044  -0.7484833  -0.70000803\n",
            "  -0.00466852  0.97987777 -0.73591757 -0.551416   -0.7943742 ]\n",
            " [-0.87792295  0.96460503 -0.9735562   0.997729   -0.98990506 -0.9176851\n",
            "  -0.9975568   0.87511784 -0.9875771  -0.999433    0.9737729  -0.9951456\n",
            "  -0.46855232 -0.9748788  -0.94204646 -0.99552923 -0.9986766  -0.9565064\n",
            "   0.97915536  0.97344357  0.95700043 -0.14756855 -0.97854125  0.16771404\n",
            "   0.14069314  0.7506561   0.9753155   0.34584257  0.28288227]\n",
            " [ 0.57239807 -0.6943446   0.6250886   0.19175191 -0.16116619  0.8176123\n",
            "  -0.44482812  0.93921703  0.9199687  -0.07112145  0.5046925  -0.08797047\n",
            "  -0.1767399  -0.9970879   0.35742375  0.24944144 -0.43863004  0.50980955\n",
            "  -0.92943496  0.21910466 -0.59842366  0.23194711  0.7744498   0.24557327\n",
            "   0.8471553   0.9412438  -0.22100665 -0.81035596 -0.01431733]\n",
            " [-0.98059386  0.8649346  -0.98825926  0.9927027  -0.9964879  -0.6726086\n",
            "  -0.9979108   0.9413369  -0.98698205 -0.99803627  0.96683437 -0.9892124\n",
            "   0.35479522 -0.9707678  -0.81461096 -0.989287   -0.9993259  -0.88211817\n",
            "   0.9191667   0.96703446  0.86155105 -0.2817986  -0.9575752   0.37192705\n",
            "   0.65522516  0.7571678   0.98856837  0.9471581   0.09675572]\n",
            " [-0.9680933   0.94491994 -0.9935125   0.99858445 -0.99286205 -0.8116758\n",
            "  -0.9986129   0.96246344 -0.984887   -0.99849564  0.992213   -0.9963604\n",
            "  -0.10826899 -0.9785971  -0.9452689  -0.9987443  -0.9990272  -0.85742486\n",
            "   0.9111958   0.993631    0.91274744  0.60178393 -0.9821485  -0.26886535\n",
            "   0.8083739   0.7932261   0.9771048   0.64955056  0.26146102]]\n",
            "150 [D loss: 0.6835, acc: 0.00%] [G loss: 0.6807, acc: 62.37%]\n",
            "Disc pred on real: [0.49 0.5  0.5  0.49 0.5 ]\n",
            "Disc pred on fake: [0.48 0.48 0.52 0.52 0.52]\n",
            "200 [D loss: 0.6822, acc: 0.00%] [G loss: 0.6790, acc: 62.97%]\n",
            "Disc pred on real: [0.49 0.49 0.49 0.49 0.73]\n",
            "Disc pred on fake: [0.5  0.48 0.49 0.5  0.53]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Generated samples at epoch 200:\n",
            "[[-0.48213157  0.99489135 -0.99852836  0.99960834 -0.99987084  0.45364317\n",
            "  -0.9999731  -0.19816639 -0.9925602  -0.9994621   0.99998564 -0.99998206\n",
            "  -0.9710741  -0.9999814  -0.33897054 -0.99962205 -0.9999845  -0.91119194\n",
            "   0.2305042   0.9801795   0.5652798  -0.7804618   0.75953984  0.26145634\n",
            "  -0.9847641   0.59905195  0.69815636 -0.97473437  0.5955724 ]\n",
            " [ 0.8142943   0.26609647 -0.9676643   0.979405   -0.8653335  -0.93605363\n",
            "  -0.9877961   0.9679165  -0.8470982  -0.9896507   0.9916358  -0.9923986\n",
            "  -0.5061049  -0.991677    0.8440443  -0.9884278  -0.9890224  -0.9629242\n",
            "  -0.47392216  0.46177885  0.9572694  -0.9228863   0.8287605   0.6383627\n",
            "  -0.62403405  0.14951943  0.9864255  -0.91018236 -0.8751364 ]\n",
            " [ 0.88769126 -0.87730396  0.9959396  -0.9999515   0.94160044  0.9996174\n",
            "   0.97185016 -0.68401694  0.9980129   0.9999914  -0.9998339   0.9999868\n",
            "   0.97701305  0.9999964  -0.5616901   0.9984711   0.99983174  0.98879695\n",
            "  -0.55496657 -0.16176394 -0.99131846 -0.809053   -0.8245355  -0.7119167\n",
            "   0.9700993  -0.5579979  -0.99981695  0.8378045   0.6616331 ]\n",
            " [ 0.9162587   0.10114761 -0.975829    0.9871969  -0.86435103 -0.9664384\n",
            "  -0.98084784  0.98086697 -0.9264826  -0.9878306   0.98225415 -0.99426883\n",
            "  -0.5630877  -0.99029535  0.87154007 -0.9877485  -0.9886587  -0.9250529\n",
            "  -0.7885774   0.72851175  0.9202227  -0.9175631   0.9619072   0.723814\n",
            "  -0.59591985 -0.19766219  0.9916394  -0.8514453  -0.8355416 ]\n",
            " [ 0.89458144  0.27338076 -0.9854948   0.9902944  -0.88275    -0.9593185\n",
            "  -0.98582095  0.98339415 -0.91425335 -0.9927939   0.9906534  -0.996083\n",
            "  -0.6033839  -0.99457085  0.88063973 -0.99231154 -0.992815   -0.9465632\n",
            "  -0.7690778   0.8462382   0.9148336  -0.92337865  0.9550037   0.67795527\n",
            "  -0.7491693  -0.22516906  0.9828455  -0.8912037  -0.8340305 ]]\n",
            "250 [D loss: 0.6811, acc: 0.00%] [G loss: 0.6795, acc: 62.19%]\n",
            "Disc pred on real: [0.71 0.49 0.49 0.49 0.49]\n",
            "Disc pred on fake: [0.52 0.49 0.48 0.49 0.49]\n",
            "300 [D loss: 0.6801, acc: 0.00%] [G loss: 0.6816, acc: 59.76%]\n",
            "Disc pred on real: [0.48 0.48 0.48 0.48 0.48]\n",
            "Disc pred on fake: [0.49 0.49 0.49 0.48 0.49]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Generated samples at epoch 300:\n",
            "[[-0.9995166  -0.99998635  1.         -1.          0.9508436   0.9987687\n",
            "   1.          0.99957293  0.20749843  1.         -1.          1.\n",
            "   0.9801149   1.          0.725754    1.          1.         -0.9990916\n",
            "   0.76390415 -0.9999859  -0.87096685 -0.99998224  0.99010783  0.9998475\n",
            "   0.24014784 -0.9968691  -0.9999938  -0.9859995  -0.7274063 ]\n",
            " [ 0.8540424   0.6117452  -0.94248044  0.9892014   0.89881116 -0.9772169\n",
            "  -0.98635083 -0.94267887  0.90751773 -0.9808339   0.97737074 -0.9928925\n",
            "   0.01175863 -0.9960877  -0.23487984 -0.9917408  -0.988965    0.47443643\n",
            "  -0.64584696  0.69434637 -0.8699797   0.37669307 -0.9298151  -0.9035601\n",
            "   0.70625    -0.5434187  -0.29572034  0.94335     0.3979626 ]\n",
            " [-0.97502565 -0.5914881   0.53217524 -0.8290222  -0.2347851   0.23819286\n",
            "   0.8755484  -0.3291429  -0.5467129   0.9421371   0.36940807  0.8279335\n",
            "  -0.222116    0.8332863   0.00769949  0.92783684  0.55242074 -0.88130844\n",
            "   0.6612782   0.35724556  0.95439476 -0.8182711  -0.10123617  0.7067008\n",
            "  -0.68902624  0.325835   -0.8017712   0.27073523  0.85972404]\n",
            " [ 0.85267335  0.4725673  -0.9501643   0.9925429   0.912919   -0.9857453\n",
            "  -0.98732764 -0.88597965  0.8309395  -0.98152375  0.9855209  -0.994317\n",
            "   0.19268945 -0.99664044 -0.16770463 -0.98901534 -0.9889894   0.76677287\n",
            "  -0.5717051   0.75908005 -0.9007458   0.617337   -0.94344497 -0.94233114\n",
            "   0.7551069  -0.24014539 -0.5899021   0.9540246   0.55756235]\n",
            " [ 0.84884834  0.5401843  -0.9420116   0.9912603   0.86679965 -0.9768633\n",
            "  -0.98657084 -0.94515544  0.86322474 -0.9780514   0.98360366 -0.9940706\n",
            "   0.05785694 -0.99603593 -0.11871724 -0.98958415 -0.987226    0.5182226\n",
            "  -0.53181624  0.68681014 -0.8811197   0.46514145 -0.9416902  -0.91623443\n",
            "   0.69305855 -0.46306464 -0.5073278   0.9482577   0.5319584 ]]\n",
            "350 [D loss: 0.6779, acc: 0.00%] [G loss: 0.6839, acc: 57.30%]\n",
            "Disc pred on real: [0.47 0.48 0.48 0.48 0.49]\n",
            "Disc pred on fake: [0.52 0.48 0.48 0.48 0.48]\n",
            "400 [D loss: 0.6776, acc: 0.00%] [G loss: 0.6872, acc: 53.95%]\n",
            "Disc pred on real: [0.48 0.48 0.74 0.48 0.48]\n",
            "Disc pred on fake: [0.48 0.48 0.5  0.48 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Generated samples at epoch 400:\n",
            "[[ 0.99997     0.63351494  0.99998903 -0.99998224 -0.99834573 -0.34524968\n",
            "   0.99998665  0.9878201   0.8981124   0.99993473 -0.9999993   0.9999998\n",
            "   0.24851906  0.99999833  0.9806534   0.99998665  0.99999     0.99382\n",
            "   0.96764165 -0.9300852  -0.997418    0.28436965 -0.92427975  0.6371955\n",
            "   0.9899371  -0.8863838  -0.99329895  0.9981785   0.72122353]\n",
            " [-0.9877535  -0.94034034 -0.99092567  0.9834858   0.39732668  0.98193526\n",
            "  -0.99917436 -0.9608046  -0.87729865 -0.9949195   0.9975895  -0.9990997\n",
            "   0.09473391 -0.9999913  -0.8962252  -0.99887186 -0.9985244  -0.9436258\n",
            "   0.8028282   0.9688873   0.79033965 -0.6523514   0.9227558  -0.81661767\n",
            "  -0.7083297   0.5856745   0.94876105 -0.9814662  -0.42256993]\n",
            " [-0.95438135  0.9845975  -0.99962795  0.99998724  1.         -0.9994037\n",
            "  -0.997634    0.98797935  0.84951735 -0.9999863   0.9999953  -0.99818856\n",
            "   0.8288674   0.9022511  -0.6994829  -0.99993134 -0.99887395 -0.67287236\n",
            "  -0.997175   -0.9968594   0.8778556   0.5051579   0.9810902  -0.29532105\n",
            "  -0.97728616  0.9146952   0.9999137  -0.988119    0.7577796 ]\n",
            " [-0.99191916 -0.942745   -0.99233526  0.9850756   0.22997437  0.98852557\n",
            "  -0.9990304  -0.9757557  -0.8930364  -0.9938167   0.997927   -0.99911225\n",
            "   0.20202191 -0.9999952  -0.893098   -0.99877316 -0.9980571  -0.9792969\n",
            "   0.85680187  0.97359157  0.7965548  -0.6944928   0.9313605  -0.823922\n",
            "  -0.65106565  0.6586877   0.9094475  -0.9840515  -0.2925474 ]\n",
            " [-0.99083734 -0.9376613  -0.99434155  0.98748386  0.36027038  0.98903626\n",
            "  -0.9990527  -0.97404194 -0.8834913  -0.99384344  0.9983787  -0.9992904\n",
            "   0.09539238 -0.9999954  -0.88695663 -0.99912435 -0.9983335  -0.9597293\n",
            "   0.8713893   0.97792727  0.73641765 -0.6781019   0.9393203  -0.83009285\n",
            "  -0.6931858   0.69189674  0.92518514 -0.98556054 -0.39024082]]\n",
            "450 [D loss: 0.6759, acc: 0.00%] [G loss: 0.6903, acc: 51.05%]\n",
            "Disc pred on real: [0.47 0.81 0.48 0.5  0.47]\n",
            "Disc pred on fake: [0.48 0.5  0.47 0.5  0.47]\n",
            "500 [D loss: 0.6752, acc: 0.00%] [G loss: 0.6944, acc: 47.49%]\n",
            "Disc pred on real: [0.52 0.47 0.47 0.47 0.47]\n",
            "Disc pred on fake: [0.49 0.47 0.47 0.47 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Generated samples at epoch 500:\n",
            "[[-0.9987985  -0.94446456  0.9892159  -0.9943256   0.9999119   0.95794326\n",
            "   0.99998826 -0.55132866  0.55178976  0.6240182  -0.18532373  0.8951951\n",
            "   0.48367366  0.9992367  -0.71808773  0.9942683   0.9960764  -0.99353945\n",
            "  -0.99757636  0.6790689  -0.99868673 -0.80735624  0.97015655 -0.85233647\n",
            "  -0.5738089   0.89691734 -0.76498663 -0.9996833  -0.37382403]\n",
            " [ 0.93713325  0.90544707 -0.991555    0.9986203  -0.5131518  -0.9610701\n",
            "  -0.9999151  -0.9187289  -0.935128   -0.9974521   0.9985938  -0.99922174\n",
            "  -0.67108876 -0.9999866  -0.16854726 -0.9975946  -0.9995078   0.8896388\n",
            "   0.97769326  0.5427892   0.8883448  -0.7086304  -0.04583412 -0.00407395\n",
            "   0.18308546  0.8421981  -0.44178125  0.9761821   0.04165997]\n",
            " [-0.9544091  -0.04829424 -0.63300467 -0.9474221  -0.16117959 -0.26431832\n",
            "   0.9240508   0.36530572 -0.9217488   0.46202686  0.68804175 -0.6376726\n",
            "  -0.23031187  0.9612893   0.89708567  0.5361821  -0.24448381  0.46090338\n",
            "  -0.9920271  -0.90123856  0.99436325  0.94958436 -0.2245246   0.10466579\n",
            "  -0.98190594  0.08630555 -0.68289065 -0.5674547   0.6435348 ]\n",
            " [ 0.941835    0.9178233  -0.9899108   0.99759406 -0.0851857  -0.9705862\n",
            "  -0.99990314 -0.89184684 -0.9242572  -0.99557114  0.9958962  -0.9982181\n",
            "  -0.43080598 -0.99998206 -0.15086257 -0.99843895 -0.9993236   0.88066274\n",
            "   0.96298754  0.70534515  0.960036   -0.6321772   0.29051355  0.44518682\n",
            "   0.36049893  0.73352563 -0.37766853  0.9720128  -0.26287043]\n",
            " [ 0.97754693  0.95206016 -0.98686683  0.999224   -0.47614995 -0.968012\n",
            "  -0.9999505  -0.9217752  -0.9123864  -0.99727464  0.99789286 -0.9987925\n",
            "  -0.5764941  -0.99999416 -0.23583622 -0.9980452  -0.99939275  0.88700366\n",
            "   0.9830479   0.67230564  0.88945395 -0.45059833 -0.13913564  0.38475618\n",
            "   0.3347133   0.80387205 -0.43734488  0.9850314  -0.1234151 ]]\n",
            "550 [D loss: 0.6737, acc: 0.00%] [G loss: 0.6974, acc: 45.10%]\n",
            "Disc pred on real: [0.82 0.47 0.47 0.85 0.46]\n",
            "Disc pred on fake: [0.49 0.47 0.47 0.49 0.47]\n",
            "600 [D loss: 0.6721, acc: 0.00%] [G loss: 0.7007, acc: 42.68%]\n",
            "Disc pred on real: [0.47 0.47 0.46 0.81 0.46]\n",
            "Disc pred on fake: [0.47 0.48 0.47 0.48 0.47]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Generated samples at epoch 600:\n",
            "[[-0.9974373   0.9552562  -0.999017    0.26184916 -0.05730102 -0.99756867\n",
            "  -0.94546235  0.80644006  0.3941608  -0.99973303  0.9998159  -0.99974257\n",
            "   0.34511957 -0.99950683 -0.49639437 -0.99803096 -0.99994385  0.41642255\n",
            "  -0.66416895 -0.993643    0.9079394   0.8755796   0.86493486  0.3947349\n",
            "   0.6235217  -0.723711   -0.9572249   0.70257074  0.6646862 ]\n",
            " [-0.99827564  0.9955398  -0.9977785   0.99676347  0.7964878  -0.9989599\n",
            "  -0.9998035   0.96235764 -0.46222854 -0.9996033   0.9999834  -0.99995726\n",
            "  -0.51884025 -0.9998982  -0.3915673  -0.99974656 -0.99998164  0.9622081\n",
            "  -0.96944994 -0.9588307   0.85529107  0.05123737  0.9538421   0.18319674\n",
            "  -0.52833194 -0.9415387  -0.98413247  0.7591181   0.8014725 ]\n",
            " [-0.86494094  0.8998229  -0.99417925 -0.61595535 -0.53151613 -0.6966211\n",
            "  -0.883181    0.9567773  -0.9717558  -0.9993261   0.97460973 -0.97156346\n",
            "  -0.7168073  -0.9962726  -0.93335664 -0.99465734 -0.9284992   0.40204972\n",
            "   0.24732201 -0.6636536   0.20495863 -0.02295216  0.42850465  0.08725821\n",
            "  -0.85311544 -0.87938493 -0.14002553  0.9562914   0.86509603]\n",
            " [-0.9980941   0.99818575 -0.9980069   0.9940329   0.8979183  -0.9992166\n",
            "  -0.99979246  0.963924   -0.56328195 -0.9995402   0.99996495 -0.9999242\n",
            "  -0.43836033 -0.9998754  -0.27685735 -0.9995702  -0.999967    0.9367471\n",
            "  -0.97614187 -0.9657046   0.9148846  -0.31678453  0.9568222   0.46027938\n",
            "  -0.6016526  -0.90701324 -0.9846355   0.39778137  0.6955214 ]\n",
            " [-0.9981115   0.9967881  -0.99865335  0.99204636  0.9133461  -0.9988299\n",
            "  -0.9995989   0.95302975 -0.58892214 -0.9996296   0.99997115 -0.99993736\n",
            "  -0.5367537  -0.9998895  -0.2884688  -0.99979126 -0.9999616   0.9443962\n",
            "  -0.9699067  -0.9634587   0.94058347 -0.34126022  0.94895315  0.25592119\n",
            "  -0.5170092  -0.91419226 -0.96241283  0.4357943   0.6548289 ]]\n",
            "650 [D loss: 0.6710, acc: 0.00%] [G loss: 0.7044, acc: 40.23%]\n",
            "Disc pred on real: [0.96 0.46 0.46 0.46 0.71]\n",
            "Disc pred on fake: [0.47 0.46 0.46 0.46 0.47]\n",
            "700 [D loss: 0.6702, acc: 0.00%] [G loss: 0.7082, acc: 37.85%]\n",
            "Disc pred on real: [0.46 0.46 0.97 0.91 0.46]\n",
            "Disc pred on fake: [0.46 0.47 0.47 0.47 0.46]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Generated samples at epoch 700:\n",
            "[[-0.9992855   0.92537916 -0.997693   -0.9994513   0.99362946 -0.9973862\n",
            "  -0.16465032 -0.97038966  0.98687804 -0.9993162  -0.4262319  -0.99822295\n",
            "   0.9982463  -0.9998842  -0.78467655  0.19759926 -0.5126003  -0.9564426\n",
            "  -0.99943596 -0.9996115   0.90744656  0.14826943 -0.8999072   0.9422763\n",
            "  -0.61326444 -0.9083009   0.6048564  -0.7930557   0.09344728]\n",
            " [ 0.98469895 -0.8710993  -0.99859375 -0.99794286 -0.99157375  0.9955473\n",
            "   0.99728185 -0.33941427 -0.9798272  -0.99938595  0.9999812  -0.99978685\n",
            "  -0.37917623 -0.99943936 -0.79531986 -0.9997995  -0.9999625  -0.99226177\n",
            "   0.9534965  -0.85093623 -0.97828525  0.02955082 -0.95541817 -0.7642738\n",
            "  -0.3989748  -0.98420423 -0.9930728   0.9756415   0.6898018 ]\n",
            " [-0.9912997  -0.58455825 -0.14627403  0.9999977   0.9566292  -0.385115\n",
            "  -0.99995846  0.86540204  0.9945508   0.9998208  -0.9999988   0.9999982\n",
            "  -0.9225858   0.9851165   0.99619204  0.99992365  0.9997157   0.99955374\n",
            "  -0.16633448  0.9865667   0.99564755 -0.99417025  0.9997457   0.9985051\n",
            "   0.8645377   0.998016    0.99998945  0.84462357 -0.79249495]\n",
            " [ 0.9817024  -0.7563884  -0.99884784 -0.9963903  -0.9784237   0.9926693\n",
            "   0.99430144 -0.3889067  -0.9826845  -0.99944854  0.9999829  -0.9998499\n",
            "  -0.3371664  -0.9996414  -0.77631366 -0.99981755 -0.99995786 -0.991995\n",
            "   0.9313045  -0.87562025 -0.97640014 -0.06317124 -0.9620452  -0.83436465\n",
            "  -0.6723814  -0.9893439  -0.9891646   0.96325994  0.66286504]\n",
            " [ 0.99175435 -0.9100538  -0.9986994  -0.99703133 -0.99125457  0.99671906\n",
            "   0.9969369  -0.22321913 -0.98835635 -0.99948007  0.99999183 -0.9998558\n",
            "  -0.4735765  -0.99956816 -0.87659657 -0.99979585 -0.9999747  -0.9920535\n",
            "   0.9710075  -0.80928975 -0.9837166  -0.08965742 -0.96414393 -0.8414101\n",
            "  -0.5133593  -0.9866466  -0.993193    0.98337364  0.73670197]]\n",
            "750 [D loss: 0.6692, acc: 0.00%] [G loss: 0.7123, acc: 35.54%]\n",
            "Disc pred on real: [0.46 0.47 0.46 0.46 0.47]\n",
            "Disc pred on fake: [0.46 0.46 0.46 0.46 0.46]\n",
            "800 [D loss: 0.6686, acc: 0.00%] [G loss: 0.7153, acc: 33.80%]\n",
            "Disc pred on real: [0.46 0.46 0.46 0.46 0.46]\n",
            "Disc pred on fake: [0.46 0.46 0.46 0.46 0.46]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Generated samples at epoch 800:\n",
            "[[ 0.99759007 -0.9999877   0.99869424 -0.98523235  0.9901065   0.99680746\n",
            "   0.99959224  0.32521123 -0.9999738   1.         -0.99999195  0.99999964\n",
            "   0.00571467  0.9999987   0.5836018  -0.992965    0.9999596  -0.9948868\n",
            "   0.9995079   0.80008566 -0.04232227 -0.33924323  0.695994   -0.3563356\n",
            "  -0.55104357  0.98808974  0.83028567 -0.45942086 -0.9011867 ]\n",
            " [-0.9907257   0.9948216  -0.9998123   0.99951935 -0.9783526  -0.999862\n",
            "  -0.9996044   0.8534002   0.9809862  -0.9999889   0.99893373 -0.9999964\n",
            "  -0.6736922  -0.9999993  -0.95502687  0.9997199  -0.9999925   0.9962891\n",
            "  -0.9956758  -0.7299787   0.87768775  0.31426397  0.7258553  -0.8037545\n",
            "  -0.5439315  -0.73675585 -0.7324812   0.5408263   0.6704533 ]\n",
            " [ 1.         -0.99815816  0.99986964 -0.99983066  0.57364136  1.\n",
            "   0.9999778  -0.82885134 -0.9951271   1.         -0.99996096  1.\n",
            "  -0.88211554  1.          0.9999673  -0.9999814   0.9999994  -0.97282684\n",
            "   0.99975187  0.9995566  -0.9999966  -0.9369439   0.1127948   0.98935497\n",
            "   0.92976063 -0.5143884   0.9990284  -0.48938805 -0.579599  ]\n",
            " [-0.99019647  0.987247   -0.9997468   0.99958456 -0.9868835  -0.99984926\n",
            "  -0.9995411   0.93488544  0.9851568  -0.99998647  0.99921834 -0.9999956\n",
            "  -0.73455715 -0.9999985  -0.9570092   0.99979687 -0.9999882   0.99445474\n",
            "  -0.9956619  -0.660459    0.9297262   0.38621753  0.8294506  -0.8425142\n",
            "  -0.31626597 -0.69869673 -0.7141346   0.654119    0.8591428 ]\n",
            " [-0.98619014  0.98354185 -0.9997299   0.99908906 -0.9723462  -0.9996809\n",
            "  -0.99963     0.8967932   0.9703524  -0.99996865  0.9986882  -0.99999356\n",
            "  -0.58218724 -0.99999785 -0.9674093   0.99941206 -0.99998254  0.9914342\n",
            "  -0.9943017  -0.7020029   0.9359621   0.05580172  0.7970967  -0.815427\n",
            "  -0.28950113 -0.81379044 -0.6363946   0.6296752   0.73144907]]\n",
            "850 [D loss: 0.6684, acc: 0.00%] [G loss: 0.7183, acc: 32.08%]\n",
            "Disc pred on real: [0.46 0.46 0.92 0.46 0.46]\n",
            "Disc pred on fake: [0.46 0.46 0.47 0.46 0.46]\n",
            "900 [D loss: 0.6681, acc: 0.00%] [G loss: 0.7211, acc: 30.41%]\n",
            "Disc pred on real: [0.46 0.99 0.93 0.46 0.46]\n",
            "Disc pred on fake: [0.45 0.46 0.46 0.46 0.46]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Generated samples at epoch 900:\n",
            "[[-0.84293085  0.97498685 -0.40642545 -0.7297482   0.9244732  -0.9990983\n",
            "  -0.86346215 -0.85868657  0.04679925 -0.9982423   0.9938086  -0.9996196\n",
            "   0.897257   -0.9986745  -0.42212802 -0.9747445  -0.9893816   0.13388692\n",
            "   0.11656014 -0.89979744  0.64228517  0.03471732 -0.95190984  0.46928388\n",
            "  -0.7042252  -0.69676244 -0.9670358   0.3376802  -0.6113943 ]\n",
            " [-0.9416249   0.07133427  0.992507    0.99990135  0.97695047 -0.96806854\n",
            "  -0.99996495  0.27575064 -0.9819233  -0.99975485 -0.9998148  -0.99951494\n",
            "  -0.95630306 -0.9999729  -0.6450875  -0.9677194  -0.9916824  -0.9971627\n",
            "   0.99767816  0.17656508  0.9934083  -0.16271853  0.6527883  -0.81714624\n",
            "   0.3633994   0.45166272 -0.9796933   0.9636777  -0.6062774 ]\n",
            " [-0.938469    0.9238958  -0.2056776  -0.958445   -0.4314514  -0.905503\n",
            "   0.9885825   0.948073   -0.8291783   0.7090463   0.9996498  -0.25304827\n",
            "  -0.49395525  0.721543    0.6737776   0.12802725  0.06926581  0.8749007\n",
            "  -0.9317815   0.8718753   0.66189516  0.8047446   0.38439816 -0.8370779\n",
            "  -0.21844254  0.61879504 -0.8973685  -0.93580115  0.4413584 ]\n",
            " [-0.96545076  0.5417445   0.99009466  0.9987281   0.98199207 -0.9852309\n",
            "  -0.99995637 -0.0691136  -0.9798268  -0.99929464 -0.99951303 -0.99963534\n",
            "  -0.7827794  -0.99995816 -0.40675178 -0.99316424 -0.99242437 -0.9894407\n",
            "   0.99748254  0.05468607  0.9963943  -0.25943413  0.4854307  -0.6950971\n",
            "   0.17677371  0.32274702 -0.954465    0.9446905  -0.7540395 ]\n",
            " [-0.95229214  0.45029762  0.9921187   0.9994999   0.98623955 -0.9772536\n",
            "  -0.9999735   0.08764105 -0.9889175  -0.9995887  -0.99973285 -0.99962646\n",
            "  -0.9038885  -0.9999642  -0.6923822  -0.9891506  -0.99311185 -0.9954232\n",
            "   0.99782276  0.1460198   0.99693453 -0.3385286   0.603177   -0.78305906\n",
            "   0.19103064  0.32267582 -0.9679107   0.94759417 -0.694263  ]]\n",
            "950 [D loss: 0.6679, acc: 0.00%] [G loss: 0.7237, acc: 28.90%]\n",
            "Disc pred on real: [0.46 0.46 0.46 0.46 0.46]\n",
            "Disc pred on fake: [0.46 0.46 0.46 0.46 0.45]\n",
            "1000 [D loss: 0.6674, acc: 0.00%] [G loss: 0.7263, acc: 27.52%]\n",
            "Disc pred on real: [0.81 0.46 0.46 0.46 0.46]\n",
            "Disc pred on fake: [0.45 0.46 0.46 0.45 0.46]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Generated samples at epoch 1000:\n",
            "[[-0.9990982  -0.58390945  0.74777186  0.16641328  0.99912274 -0.9999845\n",
            "  -0.98724717 -0.84034437 -0.8571439  -0.9993579   0.9999199  -0.9999126\n",
            "   0.980694   -0.9998925  -0.91121924 -0.99325615 -0.9965853  -0.74584836\n",
            "   0.59700495 -0.66691506  0.9975701   0.8230699  -0.6941616  -0.26996318\n",
            "  -0.03892106 -0.01798864 -0.55173826 -0.7985196  -0.9334958 ]\n",
            " [ 0.93388945  0.16628271 -0.86336493  0.9998404   0.977523    0.9905182\n",
            "  -0.9989307   0.46809575 -0.37223655 -0.99700266 -0.97414714 -0.99780303\n",
            "  -0.24794239 -0.99995923  0.96625745 -0.9936218   0.9405744   0.965618\n",
            "  -0.9896019   0.9535182  -0.9766933  -0.48311308  0.47325858 -0.58096606\n",
            "   0.42758328 -0.8650315  -0.9947727  -0.86824167 -0.5915614 ]\n",
            " [-0.9943439   0.9999916   0.94857377 -0.9887179   0.42233008 -0.9999135\n",
            "  -0.9995016  -0.6853835  -0.20232381 -0.06999555  0.9998535  -0.9998887\n",
            "  -0.41896763 -0.9028212   0.16052915 -0.86309534 -0.9981304   0.9391798\n",
            "   0.95576847 -0.90782344  0.9811297   0.5986619  -0.98509413 -0.7558592\n",
            "  -0.9743701  -0.04305001  0.02528574  0.52343637  0.6378411 ]\n",
            " [ 0.9162069   0.10928721 -0.8143401   0.99973536  0.97598714  0.98580647\n",
            "  -0.9989753   0.6131607  -0.35672206 -0.99540687 -0.96807766 -0.9977771\n",
            "  -0.07854398 -0.9999385   0.9715295  -0.9948342   0.90052944  0.97668517\n",
            "  -0.9907018   0.96095467 -0.96879447 -0.63327515  0.58099437 -0.582022\n",
            "   0.39296284 -0.8258971  -0.99368453 -0.76855594 -0.69793665]\n",
            " [ 0.89124525 -0.0935322  -0.6959456   0.99977726  0.9860484   0.97691125\n",
            "  -0.99882555  0.7494445  -0.48553866 -0.99472207 -0.97517306 -0.99698204\n",
            "   0.10973233 -0.99994874  0.9748466  -0.99292666  0.9457914   0.96423596\n",
            "  -0.99313486  0.9519048  -0.9504372  -0.46978924  0.6141371  -0.6145827\n",
            "   0.60713553 -0.92530537 -0.992054   -0.87268543 -0.5882344 ]]\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train.reshape(-1, 1)\n",
        "pos_index = np.where(y_train == 1)[0]\n",
        "neg_index = np.where(y_train == 0)[0]\n",
        "\n",
        "\n",
        "cgan.train(X_train, y_train, pos_index, neg_index, epochs=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6616aa6",
      "metadata": {
        "id": "b6616aa6"
      },
      "source": [
        "## Generating new samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91e5232",
      "metadata": {
        "id": "e91e5232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b31800-f6f8-4894-ba0a-6a3e3fc37124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7813/7813\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 14ms/step\n",
            "(250000, 29)\n"
          ]
        }
      ],
      "source": [
        "noise = np.random.normal(0, 1, (250000, 32))\n",
        "sampled_labels = np.ones(250000).reshape(-1, 1) #ones in order to only fraud data\n",
        "\n",
        "gen_samples = cgan.generator.predict([noise, sampled_labels])\n",
        "gen_samples = scaler.inverse_transform(gen_samples)\n",
        "print(gen_samples.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff881c0",
      "metadata": {
        "id": "cff881c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "610606f6-4e26-4ec3-c794-f2830bc97ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  1.548661  0.194503 -0.991635  1.418557  1.344330  1.235376 -1.229717   \n",
              "1  1.728678  0.163221 -0.962464  1.419788  1.346673  1.257320 -1.230735   \n",
              "2  1.786767 -0.314145 -0.614046  1.419874  1.339933  1.260456 -1.230968   \n",
              "3  1.613267  0.186833 -0.651335  1.419599  1.352497  1.234251 -1.230731   \n",
              "4  1.800924  0.030222 -1.181042  1.419773  1.343070  1.288580 -1.229969   \n",
              "\n",
              "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
              "0  0.833194 -0.659577 -1.078543  ...  0.713400 -0.635336 -0.374123  0.440723   \n",
              "1  0.885693 -0.277379 -1.080414  ...  0.747218 -0.698168 -0.377666  0.305396   \n",
              "2  0.933526 -0.334311 -1.078108  ...  0.765054 -0.683400 -0.348834  0.350788   \n",
              "3  0.673823 -0.652041 -1.078159  ...  0.733629 -0.650952 -0.420956  0.342058   \n",
              "4  0.871851 -0.444927 -1.078660  ...  0.751134 -0.700457 -0.353702  0.387705   \n",
              "\n",
              "        V24       V25       V26       V27       V28    Amount  \n",
              "0 -0.239748  0.307355 -0.442607 -0.386542 -0.254831  0.882664  \n",
              "1 -0.425297  0.273849 -0.434799 -0.397016 -0.289138  1.035084  \n",
              "2 -0.467051  0.373255 -0.431229 -0.397873 -0.268578  1.054472  \n",
              "3 -0.375523  0.322990 -0.405821 -0.395595 -0.252311  0.926497  \n",
              "4 -0.387925  0.315298 -0.446145 -0.397171 -0.302572  1.106383  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7018a358-13bc-4fd3-a445-7f23ec9c28d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.548661</td>\n",
              "      <td>0.194503</td>\n",
              "      <td>-0.991635</td>\n",
              "      <td>1.418557</td>\n",
              "      <td>1.344330</td>\n",
              "      <td>1.235376</td>\n",
              "      <td>-1.229717</td>\n",
              "      <td>0.833194</td>\n",
              "      <td>-0.659577</td>\n",
              "      <td>-1.078543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.713400</td>\n",
              "      <td>-0.635336</td>\n",
              "      <td>-0.374123</td>\n",
              "      <td>0.440723</td>\n",
              "      <td>-0.239748</td>\n",
              "      <td>0.307355</td>\n",
              "      <td>-0.442607</td>\n",
              "      <td>-0.386542</td>\n",
              "      <td>-0.254831</td>\n",
              "      <td>0.882664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.728678</td>\n",
              "      <td>0.163221</td>\n",
              "      <td>-0.962464</td>\n",
              "      <td>1.419788</td>\n",
              "      <td>1.346673</td>\n",
              "      <td>1.257320</td>\n",
              "      <td>-1.230735</td>\n",
              "      <td>0.885693</td>\n",
              "      <td>-0.277379</td>\n",
              "      <td>-1.080414</td>\n",
              "      <td>...</td>\n",
              "      <td>0.747218</td>\n",
              "      <td>-0.698168</td>\n",
              "      <td>-0.377666</td>\n",
              "      <td>0.305396</td>\n",
              "      <td>-0.425297</td>\n",
              "      <td>0.273849</td>\n",
              "      <td>-0.434799</td>\n",
              "      <td>-0.397016</td>\n",
              "      <td>-0.289138</td>\n",
              "      <td>1.035084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.786767</td>\n",
              "      <td>-0.314145</td>\n",
              "      <td>-0.614046</td>\n",
              "      <td>1.419874</td>\n",
              "      <td>1.339933</td>\n",
              "      <td>1.260456</td>\n",
              "      <td>-1.230968</td>\n",
              "      <td>0.933526</td>\n",
              "      <td>-0.334311</td>\n",
              "      <td>-1.078108</td>\n",
              "      <td>...</td>\n",
              "      <td>0.765054</td>\n",
              "      <td>-0.683400</td>\n",
              "      <td>-0.348834</td>\n",
              "      <td>0.350788</td>\n",
              "      <td>-0.467051</td>\n",
              "      <td>0.373255</td>\n",
              "      <td>-0.431229</td>\n",
              "      <td>-0.397873</td>\n",
              "      <td>-0.268578</td>\n",
              "      <td>1.054472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.613267</td>\n",
              "      <td>0.186833</td>\n",
              "      <td>-0.651335</td>\n",
              "      <td>1.419599</td>\n",
              "      <td>1.352497</td>\n",
              "      <td>1.234251</td>\n",
              "      <td>-1.230731</td>\n",
              "      <td>0.673823</td>\n",
              "      <td>-0.652041</td>\n",
              "      <td>-1.078159</td>\n",
              "      <td>...</td>\n",
              "      <td>0.733629</td>\n",
              "      <td>-0.650952</td>\n",
              "      <td>-0.420956</td>\n",
              "      <td>0.342058</td>\n",
              "      <td>-0.375523</td>\n",
              "      <td>0.322990</td>\n",
              "      <td>-0.405821</td>\n",
              "      <td>-0.395595</td>\n",
              "      <td>-0.252311</td>\n",
              "      <td>0.926497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.800924</td>\n",
              "      <td>0.030222</td>\n",
              "      <td>-1.181042</td>\n",
              "      <td>1.419773</td>\n",
              "      <td>1.343070</td>\n",
              "      <td>1.288580</td>\n",
              "      <td>-1.229969</td>\n",
              "      <td>0.871851</td>\n",
              "      <td>-0.444927</td>\n",
              "      <td>-1.078660</td>\n",
              "      <td>...</td>\n",
              "      <td>0.751134</td>\n",
              "      <td>-0.700457</td>\n",
              "      <td>-0.353702</td>\n",
              "      <td>0.387705</td>\n",
              "      <td>-0.387925</td>\n",
              "      <td>0.315298</td>\n",
              "      <td>-0.446145</td>\n",
              "      <td>-0.397171</td>\n",
              "      <td>-0.302572</td>\n",
              "      <td>1.106383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7018a358-13bc-4fd3-a445-7f23ec9c28d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7018a358-13bc-4fd3-a445-7f23ec9c28d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7018a358-13bc-4fd3-a445-7f23ec9c28d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c672891b-456d-4446-b0c7-c5fdae319ad7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c672891b-456d-4446-b0c7-c5fdae319ad7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c672891b-456d-4446-b0c7-c5fdae319ad7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "gen_df"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "gen_df = pd.DataFrame(data = gen_samples,\n",
        "                      columns = df.drop('Class',axis=1).columns)\n",
        "gen_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c94643cc",
      "metadata": {
        "id": "c94643cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188378b8-6982-40d3-e2e3-fc979ffbda0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470530, 29)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "gen_X_train = np.concatenate((X_train, gen_samples), axis=0)\n",
        "gen_X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce3f760",
      "metadata": {
        "id": "8ce3f760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef1ecf1-ca08-4312-9332-e286458cfa70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(470530, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "gen_y = np.ones((250000, 1))\n",
        "gen_y_train = np.concatenate((y_train, gen_y), axis=0)\n",
        "gen_y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8d8d3a",
      "metadata": {
        "id": "cb8d8d3a"
      },
      "source": [
        "## Testing baseline model with generated data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(False)\n",
        "\n",
        "# 1) Hyper-params\n",
        "SEQ_LEN = 30\n",
        "BATCH   = 32\n",
        "EPOCHS  = 5\n",
        "\n",
        "# 2) Build streaming datasets with Kerasâ€™s timeseries_dataset_from_array\n",
        "\n",
        "y_train_flat = gen_y_train.ravel()  # shape (N_train,)\n",
        "\n",
        "train_ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "    data=gen_X_train,\n",
        "    targets=y_train_flat,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    sampling_rate=1,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "    data=X_test,\n",
        "    targets=y_test,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    sampling_rate=1,\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False\n",
        ").prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "#  Build your SimpleRNN\n",
        "n_features = gen_X_train.shape[1]\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(SEQ_LEN, n_features)),\n",
        "    tf.keras.layers.SimpleRNN(50, activation='tanh'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "], name='rnn_classifier')\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(2e-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='roc_auc'),\n",
        "      tf.keras.metrics.AUC(name='pr_auc', curve='PR'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "y_prob = model.predict(val_ds).ravel()\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "\n",
        "y_true = tf.concat([y for x,y in val_ds], axis=0).numpy()\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Simple RNN on GAN-Augmented Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3DUXv4e8lVOK",
        "outputId": "74ee3b1b-2a8b-404e-9895-aa62f22ecffe"
      },
      "id": "3DUXv4e8lVOK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"rnn_classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rnn_classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚         \u001b[38;5;34m4,000\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚            \u001b[38;5;34m51\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,051\u001b[0m (15.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,051</span> (15.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,051\u001b[0m (15.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,051</span> (15.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "14704/14704 - 98s - 7ms/step - loss: 0.0158 - pr_auc: 0.9995 - precision: 0.9923 - recall: 0.9979 - roc_auc: 0.9992 - val_loss: 0.0133 - val_pr_auc: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.5010\n",
            "Epoch 2/5\n",
            "14704/14704 - 89s - 6ms/step - loss: 0.0072 - pr_auc: 0.9995 - precision: 1.0000 - recall: 0.9982 - roc_auc: 0.9992 - val_loss: 0.0131 - val_pr_auc: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.4985\n",
            "Epoch 3/5\n",
            "14704/14704 - 89s - 6ms/step - loss: 0.0063 - pr_auc: 0.9996 - precision: 1.0000 - recall: 0.9985 - roc_auc: 0.9992 - val_loss: 0.0131 - val_pr_auc: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.4999\n",
            "Epoch 4/5\n",
            "14704/14704 - 89s - 6ms/step - loss: 0.0062 - pr_auc: 0.9996 - precision: 1.0000 - recall: 0.9985 - roc_auc: 0.9993 - val_loss: 0.0131 - val_pr_auc: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.4999\n",
            "Epoch 5/5\n",
            "14704/14704 - 89s - 6ms/step - loss: 0.0061 - pr_auc: 0.9996 - precision: 1.0000 - recall: 0.9985 - roc_auc: 0.9993 - val_loss: 0.0133 - val_pr_auc: 0.0017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.4998\n",
            "\u001b[1m1722/1722\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9983    1.0000    0.9991     55009\n",
            "           1     0.0000    0.0000    0.0000        95\n",
            "\n",
            "    accuracy                         0.9983     55104\n",
            "   macro avg     0.4991    0.5000    0.4996     55104\n",
            "weighted avg     0.9966    0.9983    0.9974     55104\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referneces-[A hybrid deep learning approach with generative adversarial network for credit card fraud detection](https://doi.org/10.3390/technologies12100186), [Improving detection of credit card fraudulent transactions using generative adversarial networks](https://arxiv.org/abs/1907.03355), [Generative adversarial network for oversampling data in credit card fraud detection](https://link.springer.com/chapter/10.1007/978-3-030-36945-3_7),[ The importance of future information in credit card fraud detection](https://arxiv.org/abs/2204.05265), https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/code"
      ],
      "metadata": {
        "id": "XIVHJcrxlnSj"
      },
      "id": "XIVHJcrxlnSj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note- ChatGPT used for understanding results and help with rnn code that gave error and used entire ram.."
      ],
      "metadata": {
        "id": "pIRds91Plpia"
      },
      "id": "pIRds91Plpia"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Simple RNN with CGAN-augmented data shows the same failure pattern observed with GAN + RNN:\n",
        "\n",
        "The confusion matrix indicates that the model predicted all samples as legitimate transactions, missing all 95 fraud cases.\n",
        "\n",
        "Fraud detection metrics are precision = 0.0, recall = 0.0, F1-score = 0.0, confirming that the minority class was completely ignored.\n",
        "\n",
        "Accuracy remains extremely high at 99.83%, but this is misleading because it only reflects the dominance of the majority class.\n",
        "\n",
        "Macro averages (â‰ˆ0.50) again highlight the inability of the model to handle imbalanced data.\n",
        "\n",
        "Overall, CGAN + RNN is not effective for fraud detection. Despite using conditional GAN augmentation, the RNN model collapses to predicting only the majority class, making it unsuitable for identifying fraudulent cases."
      ],
      "metadata": {
        "id": "rF8lE6jrluc3"
      },
      "id": "rF8lE6jrluc3"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "77fELiTvlntX"
      },
      "id": "77fELiTvlntX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 310,
          "sourceId": 23498,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30822,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1846.66889,
      "end_time": "2024-12-30T03:00:04.367340",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-12-30T02:29:17.698450",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}